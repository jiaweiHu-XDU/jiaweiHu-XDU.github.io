<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Chapter 1 to 4 - Jiawei Hu - Jiawei Hu&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#3273dc"><meta name="application-name" content="Jiawei Hu - Jiawei Hu&#039;s Blog"><meta name="msapplication-TileImage" content="/img/logo.png"><meta name="msapplication-TileColor" content="#3273dc"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Jiawei Hu - Jiawei Hu&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="This is an article about Deep Learning Practice from Chapter 1 to 4."><meta property="og:type" content="blog"><meta property="og:title" content="Chapter 1 to 4"><meta property="og:url" content="https://jiaweihu-xdu.github.io/blog/Chapter1-4/"><meta property="og:site_name" content="Jiawei Hu - Jiawei Hu&#039;s Blog"><meta property="og:description" content="This is an article about Deep Learning Practice from Chapter 1 to 4."><meta property="og:locale" content="en_US"><meta property="og:image" content="https://jiaweihu-xdu.github.io/img/og_image.png"><meta property="article:published_time" content="2023-09-01T13:09:32.000Z"><meta property="article:modified_time" content="2023-12-15T06:52:23.686Z"><meta property="article:author" content="Jiawei Hu"><meta property="article:tag" content="Machine Learning"><meta property="article:tag" content="Computer Vision"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://jiaweihu-xdu.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://jiaweihu-xdu.github.io/blog/Chapter1-4/"},"headline":"Chapter 1 to 4","image":["https://jiaweihu-xdu.github.io/img/og_image.png"],"datePublished":"2023-09-01T13:09:32.000Z","dateModified":"2023-12-15T06:52:23.686Z","author":{"@type":"Person","name":"Jiawei Hu"},"publisher":{"@type":"Organization","name":"Jiawei Hu - Jiawei Hu's Blog","logo":{"@type":"ImageObject","url":"https://jiaweihu-xdu.github.io/img/logo.png"}},"description":"This is an article about Deep Learning Practice from Chapter 1 to 4."}</script><link rel="canonical" href="https://jiaweihu-xdu.github.io/blog/Chapter1-4/"><link rel="icon" href="/img/logo.png"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/6.0.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js"></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body class="is-3-column"><canvas id="universe"></canvas><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Jiawei Hu - Jiawei Hu&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">JIAWEI HU&#039;S LOG BOOK</a><a class="navbar-item" href="/blog">BLOG</a><a class="navbar-item" href="/knowledge">KNOWLEDGE</a><a class="navbar-item" href="/publications">PUBLICATIONS</a><a class="navbar-item" href="/projects">PROJECTS</a><a class="navbar-item" href="/life">LIFE</a><a class="navbar-item" href="/readings">READINGS</a><a class="navbar-item" href="/collaboration">COLLABORATION</a><a class="navbar-item" href="/archives">ARCHIVES</a><a class="navbar-item" href="/categories">CATEGORIES</a><a class="navbar-item" href="/tags">TAGS</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/jiaweiHu-XDU/jiaweiHu-XDU.github.io"><i class="fab fa-github"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Gitee" href="https://gitee.com/hujiawe_i"><i class="fa-brands fa-gofore"></i></a><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">Chapter 1 to 4</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2023-09-01T13:09:32.000Z" title="2023-09-01T13:09:32.000Z">2023-09-01</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2023-12-15T06:52:23.686Z" title="2023-12-15T06:52:23.686Z">2023-12-15</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/blog/">blog</a></span><span class="level-item"><i class="far fa-clock"></i> 11 minutes read (About 1710 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv">0</span>&nbsp;visits</span></div></div><div class="content"><h3 id="Chapter-1—Introduction-of-Deep-Learning"><a href="#Chapter-1—Introduction-of-Deep-Learning" class="headerlink" title="Chapter 1—Introduction of Deep Learning"></a>Chapter 1—Introduction of Deep Learning</h3><h4 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h4><p>In 1981, neurobiologist David Hubel discovered the mechanism of information processing in the visual system, demonstrating that the visual cortex of the brain is hierarchical. His contribution is mainly two, one is that he believes that recognizing visual functions, one is abstraction, and the other is iteration.<br>Abstraction is the abstraction of very concrete, figurative elements, that is, primitive light pixels and other information, to form meaningful concepts. These meaningful concepts will iterate upwards and become more abstract concepts that people can perceive.<br>Thus, for computers, it needs to simulate the process of abstraction and recursive iteration.</p>
<h4 id="Modern-Deep-Learning"><a href="#Modern-Deep-Learning" class="headerlink" title="Modern Deep Learning"></a>Modern Deep Learning</h4><p>Convolutional neural networks(CNN) simulate this process with convolutional layers that are usually stacked.<br>The lower convolutional layers can extract local features of the images, such as corners, edges, lines, and so on. The higher convolutional layers are able to learn more complex features from the lower convolutional layers to achieve classification and recognition of the images.</p>
<h4 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h4><p>Reinforcement Learning mainly includes 4 elements: agent, state, action, reward.</p>
<ul>
<li>Features</li>
</ul>
<blockquote>
<p>There are no supervisors, only a feedback signal.<br>Feedback is delayed and not generated immediately.<br>Reinforcement learning is sequential learning, and time has an important meaning in reinforcement learning.<br>The behavior of the agent will affect all future decisions.</p>
</blockquote>
<h3 id="Chapter-2—Deep-Learning-Framework"><a href="#Chapter-2—Deep-Learning-Framework" class="headerlink" title="Chapter 2—Deep Learning Framework"></a>Chapter 2—Deep Learning Framework</h3><h4 id="Caffe"><a href="#Caffe" class="headerlink" title="Caffe"></a>Caffe</h4><p>Caffe(Convolutional Architecture for Fast Feature Embedding): mainly used in video and image processing.<br>The official website of Caffe is <code>http://caffe.berkeleyvision.org/</code></p>
<h4 id="TensorFlow"><a href="#TensorFlow" class="headerlink" title="TensorFlow"></a>TensorFlow</h4><p>TensorFlow is an open-source database that uses data flow graphs for numerical computation. Nodes represent mathematical operations in the graph, and the lines in the graph represent multidimensional arrays of data, that is, tensors, that are related to each other between nodes.<br>Computation Graph in TensorFlow:</p>
<ul>
<li>The leaf node or start node is always a tensor.</li>
<li>Tensors cannot appear as non-leaf nodes.</li>
<li>Computational graphs always express complex operations in a hierarchical order.</li>
</ul>
<h4 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h4><p>The biggest advantage of PyTorch is that the neural network built is dynamic, while TensorFlow and Caffe are both static neural network structures.<br>The design of PyTorch follows the three levels of abstraction from low to high, $tensor\rightarrow variable(autograd)\rightarrow nn.Module$, representing high-dimensional arrays, automatic derivation, and neural networks.</p>
<h3 id="Chapter-3—Machine-Learning-Basics"><a href="#Chapter-3—Machine-Learning-Basics" class="headerlink" title="Chapter 3—Machine Learning Basics"></a>Chapter 3—Machine Learning Basics</h3><h4 id="Basic-Concepts"><a href="#Basic-Concepts" class="headerlink" title="Basic Concepts"></a>Basic Concepts</h4><ul>
<li>Loss Function: $L(y, \hat{y})$ is a measure of model error.</li>
<li>Training Error: average error on the training set.</li>
<li>Generalization Error: average error on the test set.</li>
</ul>
<p>If we unilaterally pursue the minimization of training errors, it will lead to an increase in the complexity of model parameters, resulting in overfitting of the model.<br>To prevent overfitting:</p>
<ul>
<li>Validate set tuning parameters</li>
</ul>
<p>The selection of parameters (i.e. parameter tuning) must be carried out on a dataset independent of the training and testing sets, and such a dataset used for model tuning is called a development or validation set.</p>
<ul>
<li>Loss function for regularization</li>
</ul>
<p>Regularization is added to the optimization objective to punish the complexity of redundancy.</p>
<p>$$<br>\mathop{min}\limits_{h}L(\boldsymbol{y},\boldsymbol{\hat{y}};\boldsymbol{\theta})+\lambda\cdot J(\boldsymbol{\theta})<br>$$</p>
<h4 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h4><p>Supervised learning is mainly applicable to two main types of problems: regression and classification.</p>
<ul>
<li>Classification</li>
</ul>
<p>Model evaluation metrics:</p>
<ul>
<li>Balanced problems:     $Accuracy = \frac{k}{D}$</li>
<li>Non-balanced problems:       $F-Metric$</li>
</ul>
<blockquote>
<p>Non-balanced problems<br>Define the class that is a minority of the sample as a positive class and the class that is a majority of the sample as a negative class</p>
</blockquote>
<p>【Predictions】</p>
<ul>
<li>Predict a positive sample as a positive class(true positive, TP)</li>
<li>Predict a negtive sample as a positive class(false positive, FP)</li>
<li>Predict a positive sample as a negtive class(flase negtive, FN)</li>
<li>Predict a negtive sample as a negtive class(true negtive, TN)</li>
</ul>
<p>$$<br>Define\ \ recall:\<br>R = \frac{|TP|}{|TP|+|FN|}<br>$$</p>
<p>The recall rate measures the rate of correct detection by the model among all positive samples, so it also becomes the recall rate.</p>
<p>$$<br>Define\ \ precision:\ P = \frac{|TP|}{|TP|+|FP|}<br>$$</p>
<p>The accuracy rate measures the percentage of all samples predicted by the model to be positive, and is therefore also called the accuracy rate.<br>F-Metric reconciles the average between recall and precision.</p>
<p>$$<br>F_{\alpha}=\frac{(1+\alpha^2)RP}{R+\alpha^2P}<br>$$</p>
<p>$$<br>if\ \alpha=1\Longrightarrow F_1=\frac{2RP}{R+P}<br>$$</p>
<h3 id="Chapter-4—Pytorch-Deep-Learning"><a href="#Chapter-4—Pytorch-Deep-Learning" class="headerlink" title="Chapter 4—Pytorch Deep Learning"></a>Chapter 4—Pytorch Deep Learning</h3><h4 id="Pytorch-Tensor-Features"><a href="#Pytorch-Tensor-Features" class="headerlink" title="Pytorch Tensor Features"></a>Pytorch Tensor Features</h4><ul>
<li>Tensor can use GPU for calculation</li>
<li>In the calculation, it can be automatically added to the calculation diagram as a node, and it can be automatically differentiated.</li>
</ul>
<h4 id="Tensor-Object"><a href="#Tensor-Object" class="headerlink" title="Tensor Object"></a>Tensor Object</h4><h5 id="Basic-Operations"><a href="#Basic-Operations" class="headerlink" title="Basic Operations"></a>Basic Operations</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> torch</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="string">&#x27;torch.Tensor default format:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(torch.Tensor(<span class="number">1</span>).dtype))</span><br><span class="line">torch.Tensor default <span class="built_in">format</span>:torch.float32    <span class="comment"># single point float</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="string">&#x27;torch.tensor default format:&#123;&#125;&#x27;</span>.<span class="built_in">format</span>(torch.tensor(<span class="number">1</span>).dtype))</span><br><span class="line">torch.tensor default <span class="built_in">format</span>:torch.int64    <span class="comment"># 64 bits integer</span></span><br><span class="line"><span class="comment"># Create tensor by list</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.tensor([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]],dtype=torch.float64)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(a)</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>],</span><br><span class="line">        [<span class="number">3.</span>, <span class="number">4.</span>, <span class="number">5.</span>]], dtype=torch.float64)</span><br><span class="line"><span class="comment"># Create tensor by ndarray</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.tensor(np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]]),dtype=torch.uint8)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(b)</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]], dtype=torch.uint8)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># Set tensor device</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cuda0 = torch.device(<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = torch.ones((<span class="number">2</span>,<span class="number">2</span>),device=cuda0)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(c)                       </span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>]], device=<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line"><span class="comment"># copy tensor to CPU</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = c.to(<span class="string">&#x27;cpu&#x27;</span>, torch.double)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(c.device)</span><br><span class="line">cpu</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensors multiply</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.tensor([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.tensor([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]]) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = a*b        <span class="comment"># multiply by corresponding element</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(c)</span><br><span class="line">tensor([[ <span class="number">1</span>,  <span class="number">4</span>],</span><br><span class="line">        [ <span class="number">9</span>, <span class="number">16</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = torch.mm(a, b)   <span class="comment"># multiply by metrixs</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(c)</span><br><span class="line">tensor([[ <span class="number">7</span>, <span class="number">10</span>],</span><br><span class="line">        [<span class="number">15</span>, <span class="number">22</span>]])</span><br><span class="line">   </span><br><span class="line"><span class="comment"># Special functions</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.tensor([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>]])</span><br><span class="line"><span class="comment"># Discard too small or too large elements in matrix</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.clamp(a,<span class="built_in">min</span>=<span class="number">2</span>,<span class="built_in">max</span>=<span class="number">3</span>)</span><br><span class="line">tensor([[<span class="number">2</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">3</span>]])</span><br><span class="line"><span class="comment"># Rounds to the nearest integer</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a=torch.tensor([[-<span class="number">1.2</span>, -<span class="number">1.5</span>, <span class="number">0.3</span>], [-<span class="number">0.8</span>, <span class="number">7.4</span>, <span class="number">1.2</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.<span class="built_in">round</span>(a)</span><br><span class="line">tensor([[-<span class="number">1.</span>, -<span class="number">2.</span>,  <span class="number">0.</span>],</span><br><span class="line">        [-<span class="number">1.</span>,  <span class="number">7.</span>,  <span class="number">1.</span>]])</span><br><span class="line"><span class="comment"># Hyperbolic tangent function, mapping function values to (0,1)</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.tanh(a)</span><br><span class="line">tensor([[-<span class="number">0.8337</span>, -<span class="number">0.9051</span>,  <span class="number">0.2913</span>],</span><br><span class="line">        [-<span class="number">0.6640</span>,  <span class="number">1.0000</span>,  <span class="number">0.8337</span>]])</span><br><span class="line">   </span><br><span class="line"><span class="comment"># Create tensors</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(torch.arange(<span class="number">5</span>))</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(torch.arange(<span class="number">1</span>,<span class="number">10</span>,<span class="number">2</span>))   <span class="comment"># the third parameter is foot length</span></span><br><span class="line">tensor([<span class="number">1</span>, <span class="number">3</span>, <span class="number">5</span>, <span class="number">7</span>, <span class="number">9</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(torch.linspace(<span class="number">0</span>, <span class="number">5</span>, <span class="number">10</span>))  <span class="comment"># the third parameter is elements number</span></span><br><span class="line">tensor([<span class="number">0.0000</span>, <span class="number">0.5556</span>, <span class="number">1.1111</span>, <span class="number">1.6667</span>, <span class="number">2.2222</span>, <span class="number">2.7778</span>, <span class="number">3.3333</span>, <span class="number">3.8889</span>, <span class="number">4.4444</span>, <span class="number">5.0000</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(torch.ones(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(torch.zeros((<span class="number">3</span>,<span class="number">3</span>), dtype=torch.uint8))</span><br><span class="line">tensor([[<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]], dtype=torch.uint8)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Random numbers</span></span><br><span class="line"><span class="comment"># uniform distribution of [0,1]</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.rand(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">tensor([[<span class="number">0.7228</span>, <span class="number">0.4286</span>, <span class="number">0.5304</span>],</span><br><span class="line">        [<span class="number">0.4195</span>, <span class="number">0.0597</span>, <span class="number">0.5446</span>],</span><br><span class="line">        [<span class="number">0.0225</span>, <span class="number">0.4951</span>, <span class="number">0.5704</span>]])</span><br><span class="line"><span class="comment"># elements that are sampled satisfy normal distribution</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.randn(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line">tensor([[-<span class="number">0.5142</span>,  <span class="number">0.6429</span>, -<span class="number">1.8848</span>],</span><br><span class="line">        [-<span class="number">0.7895</span>, -<span class="number">0.5115</span>,  <span class="number">0.0638</span>],</span><br><span class="line">        [ <span class="number">1.7370</span>, -<span class="number">2.2135</span>,  <span class="number">0.1514</span>]])</span><br><span class="line"><span class="comment"># uniform distribution of &#123;a,...,b&#125; and not including b</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.randint(<span class="number">0</span>,<span class="number">9</span>,(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line">tensor([[<span class="number">4</span>, <span class="number">6</span>, <span class="number">6</span>],</span><br><span class="line">        [<span class="number">3</span>, <span class="number">7</span>, <span class="number">6</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">7</span>, <span class="number">4</span>]])</span><br></pre></td></tr></table></figure>

<h5 id="Indexes-and-Slices"><a href="#Indexes-and-Slices" class="headerlink" title="Indexes and Slices"></a>Indexes and Slices</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.arange(<span class="number">9</span>).view(<span class="number">3</span>,<span class="number">3</span>) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">2</span>,<span class="number">2</span>]    <span class="comment"># basic index</span></span><br><span class="line">tensor(<span class="number">8</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[<span class="number">1</span>:, :-<span class="number">1</span>]   <span class="comment"># slice</span></span><br><span class="line">tensor([[<span class="number">3</span>, <span class="number">4</span>],</span><br><span class="line">        [<span class="number">6</span>, <span class="number">7</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[::<span class="number">2</span>]    <span class="comment"># slice with foot length</span></span><br><span class="line">tensor([[<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>rows=[<span class="number">0</span>,<span class="number">1</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>cols=[<span class="number">2</span>,<span class="number">2</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a[rows,cols]   <span class="comment"># integer index</span></span><br><span class="line">tensor([<span class="number">2</span>, <span class="number">5</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>index=a&gt;<span class="number">4</span>    <span class="comment"># bool index</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(index)</span><br><span class="line">tensor([[<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>],</span><br><span class="line">        [<span class="literal">False</span>, <span class="literal">False</span>,  <span class="literal">True</span>],</span><br><span class="line">        [ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(a[index])</span><br><span class="line">tensor([<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>])</span><br><span class="line"><span class="comment"># torch.nonzero return index matrix that corresponding value is not zero</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.randint(<span class="number">0</span>,<span class="number">2</span>,(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(a)</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>index=torch.nonzero(a)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(index)</span><br><span class="line">tensor([[<span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">0</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>],</span><br><span class="line">        [<span class="number">2</span>, <span class="number">1</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[[i,j,a[i, j]] <span class="keyword">for</span> i, j <span class="keyword">in</span> index]</span><br><span class="line">[[tensor(<span class="number">0</span>), tensor(<span class="number">0</span>), tensor(<span class="number">1</span>)], </span><br><span class="line">[tensor(<span class="number">0</span>), tensor(<span class="number">2</span>), tensor(<span class="number">1</span>)], </span><br><span class="line">[tensor(<span class="number">1</span>), tensor(<span class="number">0</span>), tensor(<span class="number">1</span>)], </span><br><span class="line">[tensor(<span class="number">1</span>), tensor(<span class="number">1</span>), tensor(<span class="number">1</span>)], </span><br><span class="line">[tensor(<span class="number">2</span>), tensor(<span class="number">1</span>), tensor(<span class="number">1</span>)]]</span><br><span class="line"><span class="comment"># torch.where(condition, x, y) if condition is true then return corresponding element in x else return the corresponding element in y. x.shape()=y.shape()</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.randn(<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = torch.ones(<span class="number">3</span>,<span class="number">2</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(x)</span><br><span class="line">tensor([[-<span class="number">1.2620</span>, -<span class="number">1.9865</span>],</span><br><span class="line">        [ <span class="number">1.1022</span>,  <span class="number">0.8017</span>],</span><br><span class="line">        [-<span class="number">0.5744</span>, -<span class="number">0.4387</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(torch.where(x&gt;<span class="number">0</span>,x,y))</span><br><span class="line">tensor([[<span class="number">1.0000</span>, <span class="number">1.0000</span>],</span><br><span class="line">        [<span class="number">1.1022</span>, <span class="number">0.8017</span>],</span><br><span class="line">        [<span class="number">1.0000</span>, <span class="number">1.0000</span>]])</span><br></pre></td></tr></table></figure>

<h5 id="Tensor-Transformation-Splicing-and-Splitting"><a href="#Tensor-Transformation-Splicing-and-Splitting" class="headerlink" title="Tensor Transformation, Splicing and Splitting"></a>Tensor Transformation, Splicing and Splitting</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.rand(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="string">&quot;the number of elements:&quot;</span>, a.nelement())  </span><br><span class="line">the number of elements: <span class="number">120</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="string">&quot;the number of axises:&quot;</span>, a.ndimension())</span><br><span class="line">the number of dimensions: <span class="number">5</span> </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="string">&quot;matrix dimension:&quot;</span>, a.size(), a.shape)   </span><br><span class="line">matrix dimension: torch.Size([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>]) torch.Size([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])  </span><br><span class="line"></span><br><span class="line"><span class="comment"># Tensor Reshape</span></span><br><span class="line"><span class="comment"># For Tensor.view, physical storage for tensors must be continuous</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.rand(<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = a.view(<span class="number">2</span>*<span class="number">3</span>,<span class="number">4</span>*<span class="number">5</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(b.shape)</span><br><span class="line">torch.Size([<span class="number">6</span>, <span class="number">20</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = a.reshape(-<span class="number">1</span>)  <span class="comment"># if set -1 in some dimension, it will be calculated automatically</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(c.shape)</span><br><span class="line">torch.Size([<span class="number">120</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = a.reshape(<span class="number">2</span>*<span class="number">3</span>, -<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(d.shape)</span><br><span class="line">torch.Size([<span class="number">6</span>, <span class="number">20</span>])</span><br><span class="line"><span class="comment"># discard some axises whose dimension is 1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.squeeze(a)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(b.shape)</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"><span class="comment"># add 1 dimension at axis 0</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>torch.unsqueeze(b,<span class="number">0</span>).shape</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tensor Transpose</span></span><br><span class="line"><span class="comment"># 2 dimensions matrix</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>&gt;&gt;&gt; b = torch.tensor([<span class="number">2</span>,<span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b</span><br><span class="line">tensor([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(torch.t(b))</span><br><span class="line">tensor([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.tensor([[<span class="number">2</span>,<span class="number">3</span>]])   <span class="comment"># transpose the outer matrix</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(torch.t(b))</span><br><span class="line">tensor([[<span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(torch.t(b[<span class="number">0</span>]))</span><br><span class="line">tensor([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(torch.transpose(b, <span class="number">1</span>, <span class="number">0</span>))</span><br><span class="line">tensor([[<span class="number">2</span>],</span><br><span class="line">        [<span class="number">3</span>]])</span><br><span class="line"><span class="comment"># high latitude matrix</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.rand((<span class="number">1</span>,<span class="number">224</span>,<span class="number">224</span>,<span class="number">3</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(a.shape) </span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">224</span>, <span class="number">224</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = a.permute(<span class="number">0</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(b.shape)</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">224</span>, <span class="number">3</span>, <span class="number">224</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tensor splicing</span></span><br><span class="line"><span class="comment"># torch.cat will splice matrices on the existed axis</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.randn(<span class="number">2</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>b = torch.randn(<span class="number">3</span>,<span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = torch.cat((a, b))    <span class="comment"># input (a, b) must be tuple because there are other attributes</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = torch.cat((b, b, b), dim=<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(c.shape)</span><br><span class="line">torch.Size([<span class="number">5</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(d.shape) </span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">9</span>])</span><br><span class="line"><span class="comment"># torch.stack will splice metrices on a new axis</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>c = torch.stack((b,b), dim=<span class="number">1</span>) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>d = torch.stack((b,b), dim=<span class="number">0</span>) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(c.shape)</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(d.shape)</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Tensor Splitting</span></span><br><span class="line"><span class="comment"># torch.split input every matrix&#x27;s size to be split</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.randn(<span class="number">10</span>, <span class="number">3</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>&gt;&gt;&gt; <span class="keyword">for</span> x <span class="keyword">in</span> torch.split(a, [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>], dim=<span class="number">0</span>):</span><br><span class="line"><span class="meta">... </span> <span class="built_in">print</span>(x.shape) </span><br><span class="line"><span class="meta">... </span></span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">torch.Size([<span class="number">4</span>, <span class="number">3</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> x <span class="keyword">in</span> torch.split(a, <span class="number">4</span>, dim=<span class="number">0</span>):    <span class="comment"># also can be an integer   </span></span><br><span class="line"><span class="meta">... </span> <span class="built_in">print</span>(x.shape)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line">torch.Size([<span class="number">4</span>, <span class="number">3</span>])</span><br><span class="line">torch.Size([<span class="number">4</span>, <span class="number">3</span>])</span><br><span class="line">torch.Size([<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># torch.chunk input matrix total number to be split</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> x <span class="keyword">in</span> torch.chunk(a, <span class="number">4</span>, dim=<span class="number">0</span>):     </span><br><span class="line"><span class="meta">... </span> <span class="built_in">print</span>(x.shape)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">torch.Size([<span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">torch.Size([<span class="number">1</span>, <span class="number">3</span>])</span><br></pre></td></tr></table></figure>

<h5 id="Tensor-Reduction"><a href="#Tensor-Reduction" class="headerlink" title="Tensor Reduction"></a>Tensor Reduction</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.tensor([<span class="number">1</span>,<span class="number">2</span>],[<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="string">&quot;global maximum value:&quot;</span>, torch.<span class="built_in">max</span>(a))  </span><br><span class="line"><span class="keyword">global</span> maximum value: tensor(<span class="number">4</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="string">&quot;colomn  maximum value:&quot;</span>, torch.<span class="built_in">max</span>(a, dim=<span class="number">0</span>))</span><br><span class="line">colomn  maximum value: torch.return_types.<span class="built_in">max</span>(</span><br><span class="line">values=tensor([<span class="number">3</span>, <span class="number">4</span>]),</span><br><span class="line">indices=tensor([<span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="string">&quot;colomn  accumulation value:&quot;</span>, torch.cumsum(a, dim=<span class="number">0</span>))</span><br><span class="line">colomn  accumulation value: tensor([[<span class="number">1</span>, <span class="number">2</span>],</span><br><span class="line">        [<span class="number">4</span>, <span class="number">6</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(<span class="string">&quot;row multiplication value:&quot;</span>, torch.cumprod(a, dim=<span class="number">1</span>))</span><br><span class="line">row multiplication value: tensor([[ <span class="number">1</span>,  <span class="number">2</span>],</span><br><span class="line">        [ <span class="number">3</span>, <span class="number">12</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.Tensor([[<span class="number">1</span>,<span class="number">2</span>], [<span class="number">3</span>,<span class="number">4</span>]])   <span class="comment"># data type to floating point</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.mean(), a.median(), a.std()</span><br><span class="line">(tensor(<span class="number">2.5000</span>), tensor(<span class="number">2.</span>), tensor(<span class="number">1.2910</span>))</span><br><span class="line"><span class="comment"># calculate with the axis</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a.mean(dim=<span class="number">0</span>), a.median(dim=<span class="number">0</span>), a.std(dim=<span class="number">0</span>)</span><br><span class="line">(tensor([<span class="number">2.</span>, <span class="number">3.</span>]), torch.return_types.median(   </span><br><span class="line">values=tensor([<span class="number">1.</span>, <span class="number">2.</span>]),</span><br><span class="line">indices=tensor([<span class="number">0</span>, <span class="number">0</span>])), tensor([<span class="number">1.4142</span>, <span class="number">1.4142</span>]))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>a = torch.randint(<span class="number">0</span>,<span class="number">3</span>,(<span class="number">3</span>,<span class="number">3</span>))</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(a)</span><br><span class="line">tensor([[<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>], </span><br><span class="line">        [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>], </span><br><span class="line">        [<span class="number">1</span>, <span class="number">0</span>, <span class="number">1</span>]])</span><br><span class="line"><span class="comment"># torchl.unique function find unique elements in the matrix</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(torch.unique(a))</span><br><span class="line">tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pytorch Tensor Automatic Differentiation</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.arange(<span class="number">9</span>).view(<span class="number">3</span>, -<span class="number">1</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x.requires_grad</span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>x = torch.rand(<span class="number">3</span>, <span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(x)</span><br><span class="line">tensor([[<span class="number">0.9214</span>, <span class="number">0.6373</span>, <span class="number">0.4736</span>],</span><br><span class="line">        [<span class="number">0.4541</span>, <span class="number">0.8828</span>, <span class="number">0.4526</span>],</span><br><span class="line">        [<span class="number">0.2727</span>, <span class="number">0.8647</span>, <span class="number">0.0488</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>w = torch.ones(<span class="number">3</span>,<span class="number">3</span>,requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(w)</span><br><span class="line">tensor([[<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">        [<span class="number">1.</span>, <span class="number">1.</span>, <span class="number">1.</span>]], requires_grad=<span class="literal">True</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y = torch.mm(w,x)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(y)</span><br><span class="line">tensor([[<span class="number">1.6481</span>, <span class="number">2.3848</span>, <span class="number">0.9750</span>],</span><br><span class="line">        [<span class="number">1.6481</span>, <span class="number">2.3848</span>, <span class="number">0.9750</span>],</span><br><span class="line">        [<span class="number">1.6481</span>, <span class="number">2.3848</span>, <span class="number">0.9750</span>]], grad_fn=&lt;MmBackward0&gt;)</span><br><span class="line"><span class="comment"># cancle tensor&#x27;s automatic differentiation</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>detached_y = y.detach()</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(detached_y)</span><br><span class="line">tensor([[<span class="number">1.6481</span>, <span class="number">2.3848</span>, <span class="number">0.9750</span>],</span><br><span class="line">        [<span class="number">1.6481</span>, <span class="number">2.3848</span>, <span class="number">0.9750</span>],</span><br><span class="line">        [<span class="number">1.6481</span>, <span class="number">2.3848</span>, <span class="number">0.9750</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>yy = torch.mean(y)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>yy.backward()        <span class="comment"># grad backward</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(y.grad)</span><br><span class="line"><span class="literal">None</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(w.grad)</span><br><span class="line">tensor([[<span class="number">0.2258</span>, <span class="number">0.1988</span>, <span class="number">0.1318</span>],</span><br><span class="line">        [<span class="number">0.2258</span>, <span class="number">0.1988</span>, <span class="number">0.1318</span>],</span><br><span class="line">        [<span class="number">0.2258</span>, <span class="number">0.1988</span>, <span class="number">0.1318</span>]])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(x.grad) </span><br><span class="line">tensor([[<span class="number">0.3333</span>, <span class="number">0.3333</span>, <span class="number">0.3333</span>],</span><br><span class="line">        [<span class="number">0.3333</span>, <span class="number">0.3333</span>, <span class="number">0.3333</span>],</span><br><span class="line">        [<span class="number">0.3333</span>, <span class="number">0.3333</span>, <span class="number">0.3333</span>]])</span><br><span class="line"><span class="comment"># with torch.no_grad() includes code snippets that do not compute differentitation</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>y =torch.<span class="built_in">sum</span>(torch.mm(w,x)) </span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="built_in">print</span>(y.requires_grad)</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">with</span> torch.no_grad():</span><br><span class="line"><span class="meta">... </span> y = torch.<span class="built_in">sum</span>(torch.mm(w,x))</span><br><span class="line"><span class="meta">... </span> <span class="built_in">print</span>(y.requires_grad)</span><br><span class="line"><span class="meta">... </span></span><br><span class="line"><span class="literal">False</span></span><br></pre></td></tr></table></figure>
</div><div class="article-licensing box"><div class="licensing-title"><p>Chapter 1 to 4</p><p><a href="https://jiaweihu-xdu.github.io/blog/Chapter1-4/">https://jiaweihu-xdu.github.io/blog/Chapter1-4/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Jiawei Hu</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2023-09-01</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2023-12-15</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Machine-Learning/">Machine Learning,</a><a class="link-muted" rel="tag" href="/tags/Computer-Vision/">Computer Vision </a></div></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=64ad5faad2ddeb0019614bc5&amp;product=inline-share-buttons&amp;source=platform" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/img/pay.png" alt="Alipay"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/img/wechat.png" alt="Wechat"></span></a><a class="button donate" href="https://www.buymeacoffee.com/DustValor" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/blog/Chapter5-8/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Chapter 5 to 8</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/blog/EBlogConfiguration/"><span class="level-item">EBlog Configuration on Icarus Theme</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://jiaweihu-xdu.github.io/blog/Chapter1-4/';
            this.page.identifier = 'blog/Chapter1-4/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'eblog-5' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-96x96 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.jpg" alt="Jiawei Hu"></figure><p class="title is-size-4 is-block" style="line-height: 'inherit'; font-family: Times New Roman">Jiawei Hu</p><p style="white-space: pre-line; font-style: italic; font-family: Times New Roman; margin-bottom: 0.50rem; font-size: 1.0em">Computer Science
Machine Learning
</p><p class="is-size-5 is-flex justify-content-center" style="font-family: Times New Roman"><i class="fas fa-map-marker-alt mr-1"></i><span>Xidian University, China</span></p></div></div></nav><nav class="level menu-list is-mobile" style="margin-bottom:1rem"><a class="level-item has-text-centered is-marginless" href="/archives"><div><p class="heading">Posts</p><div><p class="title">39</p></div></div></a><a class="level-item has-text-centered is-marginless" href="/categories"><div><p class="heading">Categories</p><div><p class="title">7</p></div></div></a><a class="level-item has-text-centered is-marginless" href="/tags"><div><p class="heading">Tags</p><div><p class="title">25</p></div></div></a></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/JiaweiHu-XDU" target="_blank" rel="noopener"><i class="fab fa-github"></i>  Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/JiaweiHu-XDU"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Cnblog" href="https://www.cnblogs.com/MarkStiff/"><i class="fa-brands fa-blogger"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Notion" href="https://zhihaoli.notion.site/"><i class="fa-solid fa-desktop"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:jiaweihu_xdu@163.com"><i class="fa-solid fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="QQ" href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=1444980878&amp;website=www.oicqzone.com"><i class="fab fa-qq"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Chapter-1—Introduction-of-Deep-Learning"><span class="level-left"><span class="level-item">1</span><span class="level-item">Chapter 1—Introduction of Deep Learning</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Background"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">Background</span></span></a></li><li><a class="level is-mobile" href="#Modern-Deep-Learning"><span class="level-left"><span class="level-item">1.2</span><span class="level-item">Modern Deep Learning</span></span></a></li><li><a class="level is-mobile" href="#Reinforcement-Learning"><span class="level-left"><span class="level-item">1.3</span><span class="level-item">Reinforcement Learning</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Chapter-2—Deep-Learning-Framework"><span class="level-left"><span class="level-item">2</span><span class="level-item">Chapter 2—Deep Learning Framework</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Caffe"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">Caffe</span></span></a></li><li><a class="level is-mobile" href="#TensorFlow"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">TensorFlow</span></span></a></li><li><a class="level is-mobile" href="#Pytorch"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">Pytorch</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Chapter-3—Machine-Learning-Basics"><span class="level-left"><span class="level-item">3</span><span class="level-item">Chapter 3—Machine Learning Basics</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Basic-Concepts"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">Basic Concepts</span></span></a></li><li><a class="level is-mobile" href="#Supervised-Learning"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">Supervised Learning</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Chapter-4—Pytorch-Deep-Learning"><span class="level-left"><span class="level-item">4</span><span class="level-item">Chapter 4—Pytorch Deep Learning</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Pytorch-Tensor-Features"><span class="level-left"><span class="level-item">4.1</span><span class="level-item">Pytorch Tensor Features</span></span></a></li><li><a class="level is-mobile" href="#Tensor-Object"><span class="level-left"><span class="level-item">4.2</span><span class="level-item">Tensor Object</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Basic-Operations"><span class="level-left"><span class="level-item">4.2.1</span><span class="level-item">Basic Operations</span></span></a></li><li><a class="level is-mobile" href="#Indexes-and-Slices"><span class="level-left"><span class="level-item">4.2.2</span><span class="level-item">Indexes and Slices</span></span></a></li><li><a class="level is-mobile" href="#Tensor-Transformation-Splicing-and-Splitting"><span class="level-left"><span class="level-item">4.2.3</span><span class="level-item">Tensor Transformation, Splicing and Splitting</span></span></a></li><li><a class="level is-mobile" href="#Tensor-Reduction"><span class="level-left"><span class="level-item">4.2.4</span><span class="level-item">Tensor Reduction</span></span></a></li></ul></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/blog/"><span class="level-start"><span class="level-item">blog</span></span><span class="level-end"><span class="level-item tag">15</span></span></a></li><li><a class="level is-mobile" href="/collaboration/"><span class="level-start"><span class="level-item">collaboration</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile" href="/knowledge/"><span class="level-start"><span class="level-item">knowledge</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/life/"><span class="level-start"><span class="level-item">life</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/projects/"><span class="level-start"><span class="level-item">projects</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/publications/"><span class="level-start"><span class="level-item">publications</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/readings/"><span class="level-start"><span class="level-item">readings</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Collaboration-Project/"><span class="tag">Collaboration Project</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/College-Life/"><span class="tag">College Life</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-Network/"><span class="tag">Computer Network</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-Principle/"><span class="tag">Computer Principle</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-Vision/"><span class="tag">Computer Vision</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Visualization/"><span class="tag">Data Visualization</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-Reinforcement-Learning/"><span class="tag">Deep Reinforcement Learning</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Eletromagnetic-B%E6%B5%8B/"><span class="tag">Eletromagnetic B测</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Eletromagnetic-Physics/"><span class="tag">Eletromagnetic Physics</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embedded-System/"><span class="tag">Embedded System</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Health/"><span class="tag">Health</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Life-Knowledge/"><span class="tag">Life Knowledge</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Life-Wisdom/"><span class="tag">Life Wisdom</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Literature-Survey/"><span class="tag">Literature Survey</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mathematical-Modeling/"><span class="tag">Mathematical Modeling</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Microcomputer/"><span class="tag">Microcomputer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenSSL/"><span class="tag">OpenSSL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Professional-Knowledge/"><span class="tag">Professional Knowledge</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Project-Habits/"><span class="tag">Project Habits</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Project-Tools/"><span class="tag">Project Tools</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reinforcement-Learning/"><span class="tag">Reinforcement Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Research-Habits/"><span class="tag">Research Habits</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Jiawei Hu - Jiawei Hu&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2023-2024 Jiawei Hu</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv"><span id="busuanzi_container_site_uv">Site UV: <span id="busuanzi_value_site_uv"></span></span>   <span id="busuanzi_container_site_pv">Site PV: <span id="busuanzi_value_site_pv"></span></span></span></p><p class="is-size-7"> </p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/jiaweiHu-XDU/jiaweiHu-XDU.github.io"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><script src="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/katex.min.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/katex.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/contrib/auto-render.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><script src="/js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><div id="dark" onclick="switchDarkMode()"></div><script type="text/javascript" src="/js/universe.js"></script></body></html>