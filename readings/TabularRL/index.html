<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Tabular Value-Based Reinforcement Learning - Jiawei Hu - Jiawei Hu&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#3273dc"><meta name="application-name" content="Jiawei Hu - Jiawei Hu&#039;s Blog"><meta name="msapplication-TileImage" content="/img/logo.png"><meta name="msapplication-TileColor" content="#3273dc"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Jiawei Hu - Jiawei Hu&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Introduce the classic, tabular, field of reinforcement learning."><meta property="og:type" content="blog"><meta property="og:title" content="Tabular Value-Based Reinforcement Learning"><meta property="og:url" content="https://jiaweihu-xdu.github.io/readings/TabularRL/"><meta property="og:site_name" content="Jiawei Hu - Jiawei Hu&#039;s Blog"><meta property="og:description" content="Introduce the classic, tabular, field of reinforcement learning."><meta property="og:locale" content="en_US"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/LZHMS/picx-images-hosting@master/EBlog/image.6ch3x1ekpyk0.webp"><meta property="article:published_time" content="2023-09-29T14:31:22.000Z"><meta property="article:modified_time" content="2023-12-15T06:54:18.552Z"><meta property="article:author" content="Jiawei Hu"><meta property="article:tag" content="Deep Reinforcement Learning"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://cdn.jsdelivr.net/gh/LZHMS/picx-images-hosting@master/EBlog/image.6ch3x1ekpyk0.webp"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://jiaweihu-xdu.github.io/readings/TabularRL/"},"headline":"Tabular Value-Based Reinforcement Learning","image":["https://cdn.jsdelivr.net/gh/LZHMS/picx-images-hosting@master/EBlog/image.6ch3x1ekpyk0.webp"],"datePublished":"2023-09-29T14:31:22.000Z","dateModified":"2023-12-15T06:54:18.552Z","author":{"@type":"Person","name":"Jiawei Hu"},"publisher":{"@type":"Organization","name":"Jiawei Hu - Jiawei Hu's Blog","logo":{"@type":"ImageObject","url":"https://jiaweihu-xdu.github.io/img/logo.png"}},"description":"Introduce the classic, tabular, field of reinforcement learning."}</script><link rel="canonical" href="https://jiaweihu-xdu.github.io/readings/TabularRL/"><link rel="icon" href="/img/logo.png"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/6.0.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js"></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body class="is-3-column"><canvas id="universe"></canvas><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Jiawei Hu - Jiawei Hu&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">JIAWEI HU&#039;S LOG BOOK</a><a class="navbar-item" href="/blog">BLOG</a><a class="navbar-item" href="/knowledge">KNOWLEDGE</a><a class="navbar-item" href="/publications">PUBLICATIONS</a><a class="navbar-item" href="/projects">PROJECTS</a><a class="navbar-item" href="/life">LIFE</a><a class="navbar-item" href="/readings">READINGS</a><a class="navbar-item" href="/collaboration">COLLABORATION</a><a class="navbar-item" href="/archives">ARCHIVES</a><a class="navbar-item" href="/categories">CATEGORIES</a><a class="navbar-item" href="/tags">TAGS</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/jiaweiHu-XDU/jiaweiHu-XDU.github.io"><i class="fab fa-github"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Gitee" href="https://gitee.com/hujiawe_i"><i class="fa-brands fa-gofore"></i></a><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">Tabular Value-Based Reinforcement Learning</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2023-09-29T14:31:22.000Z" title="2023-09-29T14:31:22.000Z">2023-09-29</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2023-12-15T06:54:18.552Z" title="2023-12-15T06:54:18.552Z">2023-12-15</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/readings/">readings</a></span><span class="level-item"><i class="far fa-clock"></i> 6 minutes read (About 828 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv">0</span>&nbsp;visits</span></div></div><div class="content"><h2 id="Reading-Notes-about-the-book-Deep-Reinforcement-Learning-written-by-Aske-Plaat"><a href="#Reading-Notes-about-the-book-Deep-Reinforcement-Learning-written-by-Aske-Plaat" class="headerlink" title="Reading Notes about the book Deep Reinforcement Learning written by Aske Plaat"></a>Reading Notes about the book <em>Deep Reinforcement Learning</em> written by Aske Plaat</h2><p>Recently, I have been reading the book <em>Deep Reinforcement Learning</em> written by Aske Plaat. This book is a good introduction to the theory of Deep Reinforcement Learning. And it is very inspiring when I learn the theory of Deep Reinforcement Learning.</p>
<h3 id="Tabular-Value-Based-Reinforcement-Learning"><a href="#Tabular-Value-Based-Reinforcement-Learning" class="headerlink" title="Tabular Value-Based Reinforcement Learning"></a>Tabular Value-Based Reinforcement Learning</h3><h4 id="Tabular-Value-Based-Agents"><a href="#Tabular-Value-Based-Agents" class="headerlink" title="Tabular Value-Based Agents"></a>Tabular Value-Based Agents</h4><p>Reinforcement learning paradigm: an agent and an environment. The origin of this concept can be traced back to the process that human interacts with the objective world. I ploted a graphical depiction to demonstrate the relationship showed as follows.</p>
<p><img src="https://cdn.jsdelivr.net/gh/LZHMS/picx-images-hosting@master/EBlog/image.6ch3x1ekpyk0.webp" alt="Fig.1 Interaction between human and the world"></p>
<ul>
<li><p>Agent and Environment<br>Formally, we can represent the relationship in the figure above.</p>
<ul>
<li>$S_t\stackrel{a_t}{\longrightarrow} S_{t+1}$</li>
<li>$S_{t+1}\stackrel{r_{t+1}}{\longrightarrow} a_{t+1}$</li>
</ul>
</li>
<li><p>Features</p>
<ul>
<li>The environment gives us only a number as an indication of the quality of an action;</li>
<li>We can generate as many action-reward pairs as we need, without a large hand-labeled dataset (action and reward, action and reward…)</li>
</ul>
</li>
</ul>
<h4 id="Markov-Decision-Process"><a href="#Markov-Decision-Process" class="headerlink" title="Markov Decision Process"></a>Markov Decision Process</h4><p>Sequential decision problems can be modelled as Markov decision processes(MDPs).<br>The Markov property</p>
<ul>
<li>the next state depends only on the current state and the actions available in it(no-memory property)</li>
</ul>
<p>Define a Markov decision process for reinforcement learning as a 5-tuple ($S, A,T_a,R_a,\gamma$)</p>
<ul>
<li><p>$S$ is a finite set of legal <em>states</em> of the environment</p>
</li>
<li><p>$A$ is a finite set of <em>actions</em>($A_s$ is the finite set of actions in state $s$)</p>
</li>
<li><p>$T_a(s, s’)=Pr(s_{t+1}=s’|s_t=s, a_t=a)$ is the probability that action $a$ in state $s$ at time $t$ will transition to state $s’$ at time $t+1$</p>
</li>
<li><p>$R_a(s,s’)$ is the <em>reward</em> received after action $a$ transitions state $s$ to state $s’$</p>
</li>
<li><p>$\gamma\in[0, 1]$ is the <em>discount factor</em> representing the difference between future and present rewards.</p>
</li>
<li><p>State $S$</p>
<ul>
<li>State Presentation: the state $s$ contains the information to uniquely represent the configuration of the environment.</li>
<li>Deterministic Environment<br>In discrete deterministic environments the transition function defines a one-step transition. That is, each action deterministically leads to a single new state.</li>
<li>Stochastic Environment<br>The outcome of the action is unknown beforehand by the agent because of continuous state space. And that result depends on elements in the environment.<br>So we can conclude that the stachastic environment determines the stochastic states.</li>
</ul>
</li>
<li><p>Action $A$</p>
<ul>
<li>An action changes the state of the environment irreversibly.</li>
<li>Actions that the agent performs are also known as its behavior, just as the human’s behavior.</li>
<li>Discrete or Continuous Action Space<ul>
<li>Action Space is related to the specific application for example, the actions in board games are discrete, while the actions in robotics are continuous.</li>
<li>Value-Based methods work well for discrete action spaces, and Policy-Based methods work well for both action spaces.</li>
</ul>
</li>
</ul>
</li>
<li><p>Transsition $T_a$</p>
<ul>
<li>Model-Free Reinforcement Learning<br>Only the environment has access to the transition function while the agent has not. In this pattern, the transition $T_a(s, s’)$ equals to the nature laws that is internal to the environment, which the agent does not know.</li>
<li>Model-Based Reinforcement Learning<br>There the agent has its own transition function, an approximation of the environment’s transition function, which is learned from the environment feedback. In my opinion, that is just our policy experince which is summarized from the past feedbacks.</li>
</ul>
</li>
</ul>
<p>The dynamics of the MDP are modelled by transition function $T_a(\cdot)$ and reward function $R_a(\cdot)$.<br>In Reinforcement Learning, reward learning is learning by backpropagation. In the dicision tree, action selection moves down, reward learning flows up. To be detailed, the downward selection policy chooses which actions to explore, and the upward propagation of the error signal performs the learning of the policy.</p>
<ul>
<li>Reward $R_a$<br>Rewards are associated with single states, indicating their quality.</li>
<li>Value Function $V^\pi(S)$<br>Usually, we are most often interested in the quality of a full decision making sequence from root to leaves. So the expected cumulative discounted future reward of a state is called the value function.</li>
<li>Discount Factor $\gamma$<br>In continuous and long running tasks it makes sense to discount rewards from far in the future in order to more strongly value current information at the present time. In my view, it’s just weights factor for every time point.</li>
<li>Policy $\pi$<br>The policy $\pi$ is a <em>conditional probability distribution</em> that for each possible state specifies the probability of each possible action. Formally, the function $\pi$ is a mapping from the state space to a probability distribution over the action space:</li>
</ul>
<p>$$<br>\pi: S\rightarrow p(A)<br>$$</p>
<p>For a particular probability from this distribution we notes: $\pi(a|s)$.<br>A special case of a policy is a <em>deterministic policy</em>, denoted by $\pi(s)$, and the mapping:</p>
<p>$$<br>\pi: S\rightarrow A<br>$$</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>Tabular Value-Based Reinforcement Learning</p><p><a href="https://jiaweihu-xdu.github.io/readings/TabularRL/">https://jiaweihu-xdu.github.io/readings/TabularRL/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Jiawei Hu</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2023-09-29</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2023-12-15</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Deep-Reinforcement-Learning/">Deep Reinforcement Learning </a></div></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=64ad5faad2ddeb0019614bc5&amp;product=inline-share-buttons&amp;source=platform" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/img/alipay.png" alt="Alipay"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/img/wechat.png" alt="Wechat"></span></a><a class="button donate" href="https://www.buymeacoffee.com/DustValor" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/collaboration/Microcomputer/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">微型计算机原理与系统设计</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/life/Wisdom/"><span class="level-item">Wisdom</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://jiaweihu-xdu.github.io/readings/TabularRL/';
            this.page.identifier = 'readings/TabularRL/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'eblog-5' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-96x96 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.jpg" alt="Jiawei Hu"></figure><p class="title is-size-4 is-block" style="line-height: 'inherit'; font-family: Times New Roman">Jiawei Hu</p><p style="white-space: pre-line; font-style: italic; font-family: Times New Roman; margin-bottom: 0.50rem; font-size: 1.0em">Computer Science
Machine Learning
</p><p class="is-size-5 is-flex justify-content-center" style="font-family: Times New Roman"><i class="fas fa-map-marker-alt mr-1"></i><span>Xidian University, China</span></p></div></div></nav><nav class="level menu-list is-mobile" style="margin-bottom:1rem"><a class="level-item has-text-centered is-marginless" href="/archives"><div><p class="heading">Posts</p><div><p class="title">33</p></div></div></a><a class="level-item has-text-centered is-marginless" href="/categories"><div><p class="heading">Categories</p><div><p class="title">6</p></div></div></a><a class="level-item has-text-centered is-marginless" href="/tags"><div><p class="heading">Tags</p><div><p class="title">23</p></div></div></a></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/JiaweiHu-XDU" target="_blank" rel="noopener"><i class="fab fa-github"></i>  Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/JiaweiHu-XDU"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Cnblog" href="https://www.cnblogs.com/MarkStiff/"><i class="fa-brands fa-blogger"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Notion" href="https://zhihaoli.notion.site/"><i class="fa-solid fa-desktop"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:jiaweihu_xdu@163.com"><i class="fa-solid fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="QQ" href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=1444980878&amp;website=www.oicqzone.com"><i class="fab fa-qq"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Reading-Notes-about-the-book-Deep-Reinforcement-Learning-written-by-Aske-Plaat"><span class="level-left"><span class="level-item">1</span><span class="level-item">Reading Notes about the book Deep Reinforcement Learning written by Aske Plaat</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Tabular-Value-Based-Reinforcement-Learning"><span class="level-left"><span class="level-item">1.1</span><span class="level-item">Tabular Value-Based Reinforcement Learning</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Tabular-Value-Based-Agents"><span class="level-left"><span class="level-item">1.1.1</span><span class="level-item">Tabular Value-Based Agents</span></span></a></li><li><a class="level is-mobile" href="#Markov-Decision-Process"><span class="level-left"><span class="level-item">1.1.2</span><span class="level-item">Markov Decision Process</span></span></a></li></ul></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/blog/"><span class="level-start"><span class="level-item">blog</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/collaboration/"><span class="level-start"><span class="level-item">collaboration</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile" href="/knowledge/"><span class="level-start"><span class="level-item">knowledge</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/life/"><span class="level-start"><span class="level-item">life</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/projects/"><span class="level-start"><span class="level-item">projects</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/readings/"><span class="level-start"><span class="level-item">readings</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Collaboration-Project/"><span class="tag">Collaboration Project</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/College-Life/"><span class="tag">College Life</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-Network/"><span class="tag">Computer Network</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-Principle/"><span class="tag">Computer Principle</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-Vision/"><span class="tag">Computer Vision</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Visualization/"><span class="tag">Data Visualization</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-Reinforcement-Learning/"><span class="tag">Deep Reinforcement Learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Eletromagnetic-B%E6%B5%8B/"><span class="tag">Eletromagnetic B测</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Eletromagnetic-Physics/"><span class="tag">Eletromagnetic Physics</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embedded-System/"><span class="tag">Embedded System</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Health/"><span class="tag">Health</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Life-Knowledge/"><span class="tag">Life Knowledge</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Life-Wisdom/"><span class="tag">Life Wisdom</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Literature-Survey/"><span class="tag">Literature Survey</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mathematical-Modeling/"><span class="tag">Mathematical Modeling</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Microcomputer/"><span class="tag">Microcomputer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenSSL/"><span class="tag">OpenSSL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Professional-Knowledge/"><span class="tag">Professional Knowledge</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Project-Tools/"><span class="tag">Project Tools</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reinforcement-Learning/"><span class="tag">Reinforcement Learning</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Jiawei Hu - Jiawei Hu&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2023-2024 Jiawei Hu</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv"><span id="busuanzi_container_site_uv">Site UV: <span id="busuanzi_value_site_uv"></span></span>   <span id="busuanzi_container_site_pv">Site PV: <span id="busuanzi_value_site_pv"></span></span></span></p><p class="is-size-7"> </p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/jiaweiHu-XDU/jiaweiHu-XDU.github.io"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><script src="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/katex.min.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/katex.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/contrib/auto-render.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><script src="/js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><div id="dark" onclick="switchDarkMode()"></div><script type="text/javascript" src="/js/universe.js"></script></body></html>