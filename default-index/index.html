<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Jiawei Hu - Jiawei Hu&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#3273dc"><meta name="application-name" content="Jiawei Hu - Jiawei Hu&#039;s Blog"><meta name="msapplication-TileImage" content="/img/logo.png"><meta name="msapplication-TileColor" content="#3273dc"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Jiawei Hu - Jiawei Hu&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta property="og:type" content="blog"><meta property="og:title" content="Jiawei Hu - Jiawei Hu&#039;s Blog"><meta property="og:url" content="https://jiaweihu-xdu.github.io/"><meta property="og:site_name" content="Jiawei Hu - Jiawei Hu&#039;s Blog"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://jiaweihu-xdu.github.io/img/og_image.png"><meta property="article:author" content="Jiawei Hu"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://jiaweihu-xdu.github.io/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://jiaweiHu-XDU.github.io"},"headline":"Jiawei Hu - Jiawei Hu's Blog","image":["https://jiaweihu-xdu.github.io/img/og_image.png"],"author":{"@type":"Person","name":"Jiawei Hu"},"publisher":{"@type":"Organization","name":"Jiawei Hu - Jiawei Hu's Blog","logo":{"@type":"ImageObject","url":"https://jiaweihu-xdu.github.io/img/logo.png"}},"description":""}</script><link rel="icon" href="/img/logo.png"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/6.0.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js"></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body class="is-3-column"><canvas id="universe"></canvas><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Jiawei Hu - Jiawei Hu&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">JIAWEI HU&#039;S LOG BOOK</a><a class="navbar-item" href="/blog">BLOG</a><a class="navbar-item" href="/knowledge">KNOWLEDGE</a><a class="navbar-item" href="/publications">PUBLICATIONS</a><a class="navbar-item" href="/projects">PROJECTS</a><a class="navbar-item" href="/life">LIFE</a><a class="navbar-item" href="/readings">READINGS</a><a class="navbar-item" href="/collaboration">COLLABORATION</a><a class="navbar-item" href="/archives">ARCHIVES</a><a class="navbar-item" href="/categories">CATEGORIES</a><a class="navbar-item" href="/tags">TAGS</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/jiaweiHu-XDU/jiaweiHu-XDU.github.io"><i class="fab fa-github"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Gitee" href="https://gitee.com/hujiawe_i"><i class="fa-brands fa-gofore"></i></a><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/collaboration/Learning&amp;Planning/">Learning &amp; Planning</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-09-02T06:42:35.340Z" title="2024-09-02T06:42:35.340Z">2024-09-02</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-09-02T06:46:46.423Z" title="2024-09-02T06:46:46.423Z">2024-09-02</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/collaboration/">collaboration</a></span><span class="level-item"><i class="far fa-clock"></i> 24 minutes read (About 3662 words)</span></div></div><div class="content"><h2 id="Learning-amp-Planning"><a href="#Learning-amp-Planning" class="headerlink" title="Learning &amp; Planning"></a>Learning &amp; Planning</h2><h3 id="1-Paper-Reading"><a href="#1-Paper-Reading" class="headerlink" title="1. Paper Reading"></a>1. Paper Reading</h3><p>/<strong>读CCF A类 期刊/会议</strong>/</p>
<p><strong>课题方向</strong>：1. 视觉问答+多模态大语言模型</p>
<p>​             2. 视频时刻定位+组合图像检索</p>
<p>​             3. 多模态疾病预测：胸片，放疗血液毒性，<strong>医疗问答</strong></p>
<h4 id="1-论文阅读方向："><a href="#1-论文阅读方向：" class="headerlink" title="1. 论文阅读方向："></a>1. 论文阅读方向：</h4><ul>
<li><p>医疗视觉问答、胸片报告生成、医疗多模态语言模型、多模态语言模型、多模态幻觉；</p>
<p>【关键词】：medical visual qustion answering、medical report generation、visual language model， multimodal large language model，image captioning，VLM、MLLM；</p>
</li>
</ul>
<h4 id="2-找论文："><a href="#2-找论文：" class="headerlink" title="2. 找论文："></a>2. 找论文：</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">website:</span><br><span class="line">https://paperswithcode.com/</span><br><span class="line">https://www.connectedpapers.com/</span><br><span class="line">https://scholar.google.com/</span><br><span class="line">https://www.semanticscholar.org/</span><br><span class="line">建议精读原文&gt;=谷歌直接翻译&gt;公众号&gt;GPT摘要，GPT会漏掉很多细节</span><br></pre></td></tr></table></figure>

<h4 id="3-论文阅读-看源码"><a href="#3-论文阅读-看源码" class="headerlink" title="3. 论文阅读+看源码"></a>3. 论文阅读+看源码</h4><h3 id="2-Skills-learned"><a href="#2-Skills-learned" class="headerlink" title="2. Skills learned"></a>2. Skills learned</h3><h4 id="1-分布式训练"><a href="#1-分布式训练" class="headerlink" title="1. 分布式训练"></a>1. 分布式训练</h4><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/ytusdc/article/details/122091284?ops_request_misc=%7B%22request_id%22:%22172484282116800175735431%22,%22scm%22:%2220140713.130102334..%22%7D&request_id=172484282116800175735431&biz_id=0&utm_medium=distribute.pc_search_result.none-task-blog-2~all~top_positive~default-1-122091284-null-null.142%5Ev100%5Epc_search_result_base2&utm_term=%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83&spm=1018.2226.3001.4187">Reference</a></p>
<ul>
<li>模型并行：模型过大单GPU显存不足无法加载，将模型切割为几个部分分别加载不同GPU</li>
<li><strong>数据并行</strong>：每个GPU复制一份模型，将一批样本分为多份分发到各个GPU进行计算，相当于加大了batch_size</li>
</ul>
<h5 id="a-Data-Parallel-DP"><a href="#a-Data-Parallel-DP" class="headerlink" title="a. Data Parallel (DP):"></a>a. Data Parallel (DP):</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">数据并行</span><br><span class="line">eg1. nn.parallel</span><br><span class="line"><span class="comment"># Replicate module to devices in device_ids</span></span><br><span class="line">replicas = nn.parallel.replicate(module, device_ids)</span><br><span class="line"><span class="comment"># Distribute input to devices in device_ids</span></span><br><span class="line">inputs = nn.parallel.scatter(<span class="built_in">input</span>, device_ids)</span><br><span class="line"><span class="comment"># Apply the models to corresponding inputs</span></span><br><span class="line">outputs = nn.parallel.parallel_apply(replicas, inputs)</span><br><span class="line"><span class="comment"># Gather result from all devices to output_device</span></span><br><span class="line">result = nn.parallel.gather(outputs, output_device)</span><br><span class="line"></span><br><span class="line">eg2. torch.nnDataParallel(module,device_ids=<span class="literal">None</span>,ouput_device=<span class="literal">None</span>,dim=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># device_ids指定在哪些GPU上进行优化，output_devices指定输出到哪个GPU上,如果不设定要使用的device_ids,程序会自动找可用的所有显卡用于训练， os.environ[&#x27;CUDA_VISIBLE_DEVICES&#x27;] == ’‘限定GPU</span></span><br><span class="line">new_net= nn.DataParallel(net, device_ids=[<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line">output= new_net(<span class="built_in">input</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">并行数据加载</span><br><span class="line">设置<span class="string">&#x27;num_workers&gt;0&#x27;</span>使用多个子进程进行数据加载</span><br></pre></td></tr></table></figure>

<p>流程：</p>
<img src="https://s2.loli.net/2024/08/28/aeiOEgAYMxnLWJp.png" alt="img" style="zoom: 80%;" />

<p>​        基本上，给定的输入通过在批处理维度中分块在GPU之间进行分配。 在前向传递中，模型在每个设备上复制，每个副本处理批次的一部分。 在向后传递过程中，主GPU（上图中的GPU-1）收集每个GPU的输出output，根据label计算loss，继而计算得到多个梯度grad，然后将梯度分发到各个GPU（官方原理图中第二行第二个），然后每个GPU副本模型上的梯度更新（第二行第三个），然后再将每个更新完梯度的的参数合并到主gpu(第二行最后一个步骤)，求和以生成最终的梯度，并将其应用于主gpu（上图中的GPU-1）以更新模型权重。 在下一次迭代中，主GPU上的更新模型将再次复制到每个GPU设备上。</p>
<h5 id="b-Distributed-Data-Parallel-DDP"><a href="#b-Distributed-Data-Parallel-DDP" class="headerlink" title="b. Distributed Data Parallel (DDP):"></a>b. <strong>Distributed Data Parallel (DDP):</strong></h5><p><img src="https://s2.loli.net/2024/08/28/Cj4Pv2hRsZdUcbO.png" alt="img"></p>
<p>​        DDP为每个GPU创建一个进程，每个进程对应一个独立的训练过程(多进程，适用单机和多机训练)，梯度计算完成后由rank=0的进程broadcast到所有进程，之后各进程用改梯度来独立的更新参数，<strong>各进程的模型参数始终保持一致</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> argparse</span><br><span class="line"><span class="keyword">from</span> torch.autograd <span class="keyword">import</span> Variable</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> torch.utils.data.distributed <span class="keyword">import</span> DistributedSampler</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 1)添加参数  --local_rank</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">每个进程分配一个 local_rank 参数, 表示当前进程在当前主机上的编号。这个参数是torch.distributed.launch传递过来的，我们设置位置参数来接受，local_rank代表当前程序进程使用的GPU标号</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">parser = argparse.ArgumentParser()</span><br><span class="line">parser.add_argument(<span class="string">&#x27;--local_rank&#x27;</span>, default=-<span class="number">1</span>, <span class="built_in">type</span>=<span class="built_in">int</span>,</span><br><span class="line">                    <span class="built_in">help</span>=<span class="string">&#x27;node rank for distributed training&#x27;</span>)</span><br><span class="line">args = parser.parse_args()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 通过args接收 local_rank</span></span><br><span class="line">local_rank = args.local_rank</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 通过 get_rank() 得到 local_rank，最好放在初始化之后使用</span></span><br><span class="line">local_rank = torch.distributed.get_rank()</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 2)********************************************************</span></span><br><span class="line"><span class="comment"># 初始化使用nccl后端</span></span><br><span class="line">torch.distributed.init_process_group(backend=<span class="string">&quot;nccl&quot;</span>)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 3)********************************************************</span></span><br><span class="line"><span class="comment"># 获取 local_rank</span></span><br><span class="line">local_rank = torch.distributed.get_rank()</span><br><span class="line"><span class="comment">#配置每个进程的 GPU， 根据local_rank来设定当前使用哪块GPU</span></span><br><span class="line">torch.cuda.set_device(local_rank)</span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span>, local_rank)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 4)********************************************************</span></span><br><span class="line"><span class="comment"># 自己的数据获取</span></span><br><span class="line">dataset = MyDataset(input_size, data_size)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 使用 DistributedSampler</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">使用 DistributedSampler 对数据集进行划分。它能帮助我们将每个 batch 划分成几个 partition，在当前进程中只需要获取和 rank 对应的那个 partition 进行训练</span></span><br><span class="line"><span class="string">#注意 testset不用sampler</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">train_sampler = torch.utils.data.distributed.DistributedSampler(dataset)</span><br><span class="line"> </span><br><span class="line">trainloader = DataLoader(dataset=dataset,</span><br><span class="line">                         pin_memory=true,</span><br><span class="line">                         shuffle=(train_sampler <span class="keyword">is</span> <span class="literal">None</span>),   <span class="comment"># 使用分布式训练 shuffle 应该设置为 False</span></span><br><span class="line">                         batch_size=args.batch_size,</span><br><span class="line">                         num_workers=args.workers,</span><br><span class="line">                         sampler=train_sampler)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 5)********************************************************</span></span><br><span class="line">model = Model()</span><br><span class="line"><span class="comment"># 把模型移到对应的gpu</span></span><br><span class="line"><span class="comment"># 定义并把模型放置到单独的GPU上，需要在调用`model=DDP(model)`前做</span></span><br><span class="line">model.to(device)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># 引入SyncBN，这句代码，会将普通BN替换成SyncBN。</span></span><br><span class="line">model = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model)</span><br><span class="line"> </span><br><span class="line"><span class="comment"># GPU 数目大于 1 才有必要分布式训练</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.device_count() &gt; <span class="number">1</span>:</span><br><span class="line">    model = torch.nn.parallel.DistributedDataParallel(model,</span><br><span class="line">                                                      device_ids=[local_rank],</span><br><span class="line">                                                      output_device=local_rank)</span><br><span class="line"> </span><br><span class="line"> </span><br><span class="line"><span class="comment"># 6)********************************************************</span></span><br><span class="line"> </span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    <span class="comment"># 设置sampler的epoch，DistributedSampler需要这个来维持各个进程之间的相同随机数种子</span></span><br><span class="line">    trainloader.sampler.set_epoch(epoch)</span><br><span class="line">    <span class="comment"># 后面这部分，则与原来完全一致了。</span></span><br><span class="line">    <span class="keyword">for</span> data, label <span class="keyword">in</span> trainloader:</span><br><span class="line">        prediction = model(data)</span><br><span class="line">        loss = loss_fn(prediction, label)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer = optim.SGD(ddp_model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line">        optimizer.step()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">eg</span><br><span class="line">CUDA_VISIBLE_DEVICES=<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span> python -m torch.distributed.launch --nproc_per_node=<span class="number">4</span> main.py --&#123;args&#125;</span><br><span class="line"><span class="comment"># --nproc_per_node一般设定为当前主机可用的GPU数目</span></span><br></pre></td></tr></table></figure>

<h5 id="c-Hugging-Face-Accelerate"><a href="#c-Hugging-Face-Accelerate" class="headerlink" title="c. Hugging Face Accelerate:"></a>c. <strong>Hugging Face Accelerate</strong>:</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">Eg</span><br><span class="line"><span class="keyword">from</span> transformers <span class="keyword">import</span> BertForSequenceClassification, AdamW, get_scheduler</span><br><span class="line"><span class="keyword">from</span> datasets <span class="keyword">import</span> load_dataset</span><br><span class="line"><span class="keyword">from</span> accelerate <span class="keyword">import</span> Accelerator</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化 Accelerator</span></span><br><span class="line">accelerator = Accelerator()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">dataset = load_dataset(<span class="string">&quot;glue&quot;</span>, <span class="string">&quot;mrpc&quot;</span>)</span><br><span class="line">train_dataset = dataset[<span class="string">&quot;train&quot;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型和优化器</span></span><br><span class="line">model = BertForSequenceClassification.from_pretrained(<span class="string">&quot;bert-base-uncased&quot;</span>)</span><br><span class="line">optimizer = AdamW(model.parameters(), lr=<span class="number">5e-5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备数据加载器</span></span><br><span class="line">train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 准备模型、数据和优化器</span></span><br><span class="line">model, optimizer, train_dataloader = accelerator.prepare(model, optimizer, train_dataloader)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练循环</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> train_dataloader:</span><br><span class="line">        outputs = model(**batch)</span><br><span class="line">        loss = outputs.loss</span><br><span class="line">        accelerator.backward(loss)</span><br><span class="line">        optimizer.step()</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;Epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>, Loss: <span class="subst">&#123;loss.item()&#125;</span>&#x27;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://blog.variantconst.com/posts/accelerate-config/">Accelerate config</a></p>
<p><strong>mutil GPU config</strong></p>
<ul>
<li><p>How many different machines will you use (use more than 1 for multi-node training)?<br>– 在几台机器(物理意义)上训练</p>
</li>
<li><p>Should distributed operations be checked while running for errors? This can avoid timeout issues but will be slower. [yes/NO]:</p>
<p>– 启用这个选项可以帮助你避免因为错误导致的超时问题，但可能会降低训练速度</p>
</li>
<li><p>Do you wish to optimize your script with torch dynamo?[yes/NO]:  </p>
<p>– Torch Dynamo 是 PyTorch 的一个新特性，用于通过动态跟踪和编译 Python 代码来提升模型的运行效率。如果你希望通过这个工具提高模型训练或推理的速度，可以选择 <code>yes</code>。</p>
</li>
<li><p>Do you want to use DeepSpeed? [yes/NO]: </p>
<p>– DeepSpeed 是微软开发的一个深度学习优化库，专门用于高效的分布式训练。它可以显著提高大规模模型的训练速度，减少显存占用，并支持混合精度训练。如果你正在训练一个大型模型并且希望提高训练效率，可以选择 <code>yes</code>。</p>
</li>
<li><p>Do you want to use FullyShardedDataParallel? [yes/NO]:  </p>
<p>– 选择 <code>yes</code>：如果决定启用 FSDP，PyTorch 会自动在训练中使用 FSDP 进行优化。你可能还需要根据实际情况配置 FSDP 相关的参数。</p>
<p>选择 <code>no</code>：如果选择 <code>no</code>，则不会启用 FSDP，训练将不会使用这种内存优化策略。</p>
</li>
<li><p>Do you want to use Megatron-LM ? [yes/NO]: </p>
</li>
</ul>
<p>选择 <code>yes</code>：如果决定启用 Megatron-LM，你可能需要进行额外的配置和调整来确保其正确集成到你的训练过程。</p>
<p>选择 <code>no</code>：如果选择 <code>no</code>，训练将不会使用 Megatron-LM，通常会依赖于默认的训练设置和策略。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">accelerate configuration saved at /home/dell/.cache/huggingface/accelerate/default_config.yaml</span><br></pre></td></tr></table></figure>

<h4 id="2-Common-Screen-Commands"><a href="#2-Common-Screen-Commands" class="headerlink" title="2. Common Screen Commands"></a>2. Common Screen Commands</h4><p>**Introduction:**In project development, when executing programs on the Linux terminal, if the terminal is closed, the program execution will also terminate. This poses significant inconvenience for long-running programs.</p>
<p>Screen facilitates the management of multiple command-line workflows without concern for their interference. Programs are automatically backgrounded and continue execution until completion.</p>
<h5 id="Start-a-New-screen-Session"><a href="#Start-a-New-screen-Session" class="headerlink" title="Start a New screen Session"></a>Start a New <code>screen</code> Session</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Start a new screen session named &quot;my_session&quot;</span></span><br><span class="line">screen -S my_session</span><br><span class="line"><span class="comment"># Automatically name the new screen session</span></span><br><span class="line">screen</span><br></pre></td></tr></table></figure>

<h5 id="View-Existing-screen-Sessions"><a href="#View-Existing-screen-Sessions" class="headerlink" title="View Existing screen Sessions"></a>View Existing <code>screen</code> Sessions</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># List all screen sessions</span></span><br><span class="line">screen -<span class="built_in">ls</span></span><br></pre></td></tr></table></figure>

<h5 id="Attach-to-an-Existing-screen-Session"><a href="#Attach-to-an-Existing-screen-Session" class="headerlink" title="Attach to an Existing screen Session"></a>Attach to an Existing <code>screen</code> Session</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Attach to the screen session named &quot;my_session&quot;</span></span><br><span class="line">screen -r my_session</span><br></pre></td></tr></table></figure>

<h5 id="Detach-from-an-Existing-screen-Session"><a href="#Detach-from-an-Existing-screen-Session" class="headerlink" title="Detach from an Existing screen Session"></a>Detach from an Existing <code>screen</code> Session</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Way 1</span></span><br><span class="line"><span class="comment"># Detach from the screen session named &quot;my_session&quot;</span></span><br><span class="line">screen -d my_session</span><br><span class="line"><span class="comment"># Way 2</span></span><br><span class="line"><span class="comment"># Enter the following keys in turn and the program</span></span><br><span class="line"><span class="comment"># will also continue to execute in the background</span></span><br><span class="line">Ctrl+a</span><br><span class="line">a</span><br></pre></td></tr></table></figure>

<h5 id="Delete-an-Existing-screen-Session"><a href="#Delete-an-Existing-screen-Session" class="headerlink" title="Delete an Existing screen Session"></a>Delete an Existing <code>screen</code> Session</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Delete the screen session named &quot;my_session&quot;</span></span><br><span class="line">screen -X -S my_session quit</span><br></pre></td></tr></table></figure>

<h5 id="Eg"><a href="#Eg" class="headerlink" title="Eg"></a>Eg</h5><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">安装：</span><br><span class="line">apt-get update</span><br><span class="line">apt-get install screen</span><br><span class="line">screen -S phi3v</span><br><span class="line">screen -r phi3v</span><br><span class="line">screen -Q -S phi3v </span><br><span class="line">删除：screen -S 12345 -X quit</span><br><span class="line">强制附加到已经附加的 screen 会话</span><br><span class="line">screen -dr phi3v</span><br></pre></td></tr></table></figure>

<h4 id="3-Zip-环境移植"><a href="#3-Zip-环境移植" class="headerlink" title="3. Zip 环境移植"></a>3. Zip 环境移植</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cd 对应的环境envs文件夹</span><br><span class="line">zip -r envs_name.zip envs_name</span><br><span class="line">使用winscp等工具传输至服务器conda环境文件夹</span><br><span class="line">unzip envs_name.zip</span><br><span class="line">激活</span><br><span class="line"></span><br><span class="line">遇到未初始化无法激活：直接用完整路径激活环境：source /opt/conda/bin/activate phi3v</span><br><span class="line"></span><br><span class="line">使用 sed 命令来批量替换所有脚本文件中的解释器路径</span><br><span class="line">find /opt/conda/envs/phi3v/bin/ -type f -exec sed -i &#x27;s|/home/dell/.conda/envs/phi3v/bin/python|/opt/conda/envs/phi3v/bin/python|g&#x27; &#123;&#125; +</span><br><span class="line">这条命令会遍历 /opt/conda/envs/phi3v/bin/ 目录下的所有文件，并将旧的解释器路径 /home/dell/.conda/envs/phi3v/bin/python 替换为新的路径 /opt/conda/envs/phi3v/bin/python。</span><br><span class="line"></span><br><span class="line"># 找不到库</span><br><span class="line">conda deactivate 两次</span><br><span class="line">conda activate envs_names</span><br></pre></td></tr></table></figure>

<h4 id="4-Docker使用"><a href="#4-Docker使用" class="headerlink" title="4. Docker使用"></a>4. Docker使用</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">E.g  (docker命令只在宿主机内有效)</span><br><span class="line">docker run --gpus all -it --shm-size 128g -v /mnt/exdisk/maz:/workspace --name my_container maz:latest /bin/bash</span><br><span class="line">eg:   docker exec -it 64e /bin/bash</span><br><span class="line">docker exec -it &lt;容器ID或容器名称&gt; /bin/bash</span><br></pre></td></tr></table></figure>

<img src="https://s2.loli.net/2024/08/22/PbphZCDXrJNBgnW.png" alt="image-20240822231204208" style="zoom:67%;" />

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">命令小结</span><br><span class="line"><span class="comment"># 安装docker</span></span><br><span class="line">yum install docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># 开启docker服务：</span></span><br><span class="line">service docker start</span><br><span class="line"></span><br><span class="line"><span class="comment"># 列出所有docker镜像的命令：</span></span><br><span class="line">docker images</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除指定docker镜像的命令：</span></span><br><span class="line">docker rmi anibali/pytorch</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载一个新的镜像的命令：</span></span><br><span class="line">docker pull anibali/pytorch:1.7.0-cuda11.0</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行新镜像，创建一个cpu运行的容器</span></span><br><span class="line"><span class="comment"># -i: 交互式操作。</span></span><br><span class="line"><span class="comment"># -t: 终端。</span></span><br><span class="line"><span class="comment"># /bin/bash：放在镜像名后的是命令，这里我们希望有个交互式 Shell，因此用的是 /bin/bash</span></span><br><span class="line">docker run -it --name torch_cpu anibali/pytorch:1.7.0-cuda11.0 /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 运行新镜像，创建一个gpu运行的容器</span></span><br><span class="line">docker run -it --name torch_gpu --gpus all anibali/pytorch:1.7.0-cuda11.0 /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看所有的容器命令如下：</span></span><br><span class="line">docker ps -a</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看当前正在运行的容器命令如下：</span></span><br><span class="line">docker ps -l</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动已被停止的容器</span></span><br><span class="line">docker start CONTAINER_ID/CONTAINER_NAME</span><br><span class="line"></span><br><span class="line"><span class="comment"># 停止运行中的容器</span></span><br><span class="line">docker stop CONTAINER_ID/CONTAINER_NAME</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重启容器</span></span><br><span class="line">docker restart CONTAINER_ID/CONTAINER_NAME</span><br><span class="line"></span><br><span class="line"><span class="comment"># 删除容器(-f是指强制执行)</span></span><br><span class="line">docker <span class="built_in">rm</span> -f CONTAINER_ID/CONTAINER_NAME</span><br><span class="line">docker <span class="built_in">rm</span> CONTAINER_ID/CONTAINER_NAME</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入容器</span></span><br><span class="line">docker <span class="built_in">exec</span> -it CONTAINER_ID/CONTAINER_NAME /bin/bash</span><br><span class="line"></span><br><span class="line"><span class="comment"># 重命名容器</span></span><br><span class="line"><span class="comment"># docker rename &lt;Old_Name&gt; &lt;New_Name&gt;</span></span><br><span class="line">docker rename testtorch torch_gpu</span><br><span class="line"></span><br><span class="line"><span class="comment"># 拷贝本地文件到容器</span></span><br><span class="line"><span class="comment"># docker cp 本地路径 容器ID:容器路径</span></span><br><span class="line"><span class="comment"># docker cp &lt;Local_File&gt; &lt;CONTAINER_ID/CONTAINER_NAME&gt;:/workspace/</span></span><br><span class="line">docker <span class="built_in">cp</span> MLP 95909784d85b:/workspace/</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看容器端口的映射情况</span></span><br><span class="line">docker port CONTAINER_ID/CONTAINER_NAME</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定宿主机与容器端口的映射(通过参数-p指定端口映射)</span></span><br><span class="line">docker run -it -d --name CONTAINER_NAME -p 8088:80 IMAGE_NAME</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存容器为镜像</span></span><br><span class="line">docker commit -a &lt;Auther_Name&gt; &lt;CONTAINER_ID/CONTAINER_NAME&gt; &lt;Version_Number&gt;</span><br></pre></td></tr></table></figure>

<h3 id="3-LLM-amp-多模态模型"><a href="#3-LLM-amp-多模态模型" class="headerlink" title="3. LLM &amp; 多模态模型"></a>3. LLM &amp; 多模态模型</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CLIP-&gt;BLIP-&gt;BLIPv2-&gt;InstructBLIP-&gt;LLAVA-&gt;MINIGPT4</span><br></pre></td></tr></table></figure>

<h4 id="0-理论基础"><a href="#0-理论基础" class="headerlink" title="0. 理论基础"></a>0. 理论基础</h4><p><strong>Fine-tuning</strong>: 在预训练模型(通常在一些大规模的通用数据集上训练，可以视作一个基础模型，能够在广泛任务中发挥作用)基础上，通过进一步训练，使其适应特定任务或领域的过程，微调则是在特定数据集上额外训练，以提高模型在特定任务上的性能。</p>
<p><strong>【<a target="_blank" rel="noopener" href="https://intro-llm.github.io/#chapter">大规模语言模型：从理论到实践 (intro-llm.github.io)</a>】</strong></p>
<h4 id="torchkeras—LLM微调"><a href="#torchkeras—LLM微调" class="headerlink" title="torchkeras—LLM微调"></a>torchkeras—LLM微调</h4><h4 id="CLIP"><a href="#CLIP" class="headerlink" title="CLIP"></a>CLIP</h4><p><a target="_blank" rel="noopener" href="https://github.com/openai/CLIP">GitHub - openai/CLIP: CLIP (Contrastive Language-Image Pretraining), Predict the most relevant text snippet given an image</a></p>
<ul>
<li>ClIP如何进行预训练：</li>
</ul>
<hr>
<p>输入：图片+文字的配对   </p>
<p>进入Encoder，生成特征，在特征上作对比学习，特征矩阵里获得正样本和负样本</p>
<ul>
<li>提出了 <code>prompt engineering</code>和<code>prompt ensemble</code>两种方式来提高模型的准确率</li>
</ul>
<p>– 识别图片机制：用图片给到图片编码器，再去和ImageNet的1000个分类词作相关性匹配，把相关性最大的词挑出来，即完成分类。</p>
<ul>
<li>有趣的应用：</li>
</ul>
<ol>
<li>生成图</li>
<li>物体的分割和检测</li>
<li>视频检索(OCR)</li>
</ol>
<img src="https://i0.hdslb.com/bfs/note/243ca05274f9e9008dd27db08515e0cd64aa1b33.jpg@670w_!web-note.webp" alt="img" style="zoom:80%;" />

<p><strong>Prompt engineering</strong></p>
<p>为什么要做：</p>
<ol>
<li>Prompt的多义性</li>
<li>预训练时基本都是一个句子，很少是一个单词，可如果做推理的时候，输入只是单词，抽取出来的特征可能就不好</li>
</ol>
<p>CLIP的解决方案：Prompt template：“A photo of a {label}”</p>
<p>使用了这个template后，准确度提升了1.3%</p>
<ul>
<li>CLIP工作最大的贡献，在于<strong>打破了固定种类标签的范式</strong>。</li>
</ul>
<p>【<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_38252409/article/details/133828294#:~:text=1.%E5%AE%98%E6%96%B9%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E5%AE%98%E7%BD%91%E4%BB%A3%E7%A0%81%E5%AE%89%E8%A3%85%E5%A6%82%E4%B8%8B%E5%91%BD%E4%BB%A4%EF%BC%9A2.CLIP%E7%8E%AF%E5%A2%83%E5%AE%89%E8%A3%85%E6%9E%84%E5%BB%BA%E8%99%9A%E6%8B%9F%E7%8E%AF%E5%A2%83%EF%BC%9A%E5%AE%89%E8%A3%85torch%E7%9B%B8%E5%85%B3%E5%8C%85%EF%BC%9A%E5%AE%89%E8%A3%85%E7%9B%B8%E5%85%B3%E4%BE%9D%E8%B5%96%E5%8C%85%EF%BC%9A%E8%BF%90%E8%A1%8C%E6%BA%90">CLIP源码解析</a>】</p>
<h4 id="Phi3v"><a href="#Phi3v" class="headerlink" title="Phi3v"></a>Phi3v</h4><h3 id="Todo-Task"><a href="#Todo-Task" class="headerlink" title="Todo-Task"></a>Todo-Task</h3><ol>
<li><p>熟悉phi2、phi3的训练代码，在4090上把MIMIC-CXR的对齐跑起来</p>
</li>
<li><p>Captioning评估指标代码(BLEU、ROUGE、F1等等)</p>
</li>
<li><p>测phi3-v在三个数据集的zero-shot精度(EXMatch)</p>
</li>
<li><p>测phi3-v在LLaVA-Med的精度(人类评估、GPT4评估)</p>
</li>
</ol>
<p>建议先试试phi-3v能不能跑（4090不支持flash-attention，可能显存会不够）：<br>1、先把mimic数据整理成PubMed对齐数据一样（参考/data/liangx/Phi-3CookBook/data/）<br>2、参考/data/liangx/Phi-3CookBook/src/dataset/* 写数据集读取的类<br>3、改训练代码；</p>
<hr>
<p>这是Phi3-V的代码：<a target="_blank" rel="noopener" href="https://github.com/microsoft/Phi-3CookBook/blob/main/code/04.Finetuning/vision_finetuning/finetune_hf_trainer_docvqa.py">https://github.com/microsoft/Phi-3CookBook/blob/main/code/04.Finetuning/vision_finetuning/finetune_hf_trainer_docvqa.py</a><br>文档：<a target="_blank" rel="noopener" href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/04.Fine-tuning/FineTuning_Vision.md">https://github.com/microsoft/Phi-3CookBook/blob/main/md/04.Fine-tuning/FineTuning_Vision.md</a></p>
<hr>
<p>Phi2的代码：<a target="_blank" rel="noopener" href="https://github.com/DLYuanGod/TinyGPT-V/tree/main">https://github.com/DLYuanGod/TinyGPT-V/tree/main</a><br>论文：TinyGPT-V: Efficient Multimodal Large Language Model via Small Backbones</p>
<p>Captioning评估代码可以参考（137行）<a target="_blank" rel="noopener" href="https://github.com/ecoxial2007/DCG_Enhanced_distilGPT2/blob/main/train_ver4_iu_xray.py">https://github.com/ecoxial2007/DCG_Enhanced_distilGPT2/blob/main/train_ver4_iu_xray.py</a></p>
<p>直接用 /data/liangx/Phi-3CookBook/llava-qa_eval_after.json 去试，能输出coco和chexbert几个指标就行</p>
</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Collaboration-Project/">Collaboration Project </a></div></div></article></div><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/collaboration/soc%E5%A4%8D%E4%B9%A0/">SOC微体系结构设计</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-05-26T05:35:35.354Z" title="2024-05-26T05:35:35.354Z">2024-05-26</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-05-26T05:35:19.255Z" title="2024-05-26T05:35:19.255Z">2024-05-26</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/collaboration/">collaboration</a></span><span class="level-item"><i class="far fa-clock"></i> 21 minutes read (About 3141 words)</span></div></div><div class="content">SOC微体系结构设计</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><a class="article-more button is-small is-size-7" href="/collaboration/soc%E5%A4%8D%E4%B9%A0/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/blog/Typora%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95%E6%95%B4%E7%90%86/">Common syntax for Typroa</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-05-02T05:15:09.637Z" title="2024-05-02T05:15:09.637Z">2024-05-02</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-05-02T05:26:11.767Z" title="2024-05-02T05:26:11.767Z">2024-05-02</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/blog/">blog</a></span><span class="level-item"><i class="far fa-clock"></i> 2 minutes read (About 335 words)</span></div></div><div class="content">This is a brief introduction to the common syntax for blogging with Typora</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Project-Tools/">Project Tools </a></div><a class="article-more button is-small is-size-7" href="/blog/Typora%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95%E6%95%B4%E7%90%86/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/collaboration/%E8%A5%BF%E7%94%B5B%E6%B5%8B%E8%AE%A1%E7%BD%91%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/">西电计科B测——计算机网络综合实验</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-04-27T15:49:40.732Z" title="2024-04-27T15:49:40.732Z">2024-04-27</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-04-27T16:10:42.983Z" title="2024-04-27T16:10:42.983Z">2024-04-28</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/collaboration/">collaboration</a></span><span class="level-item"><i class="far fa-clock"></i> 30 minutes read (About 4488 words)</span></div></div><div class="content">计科B测——计算机网络综合实验</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Collaboration-Project/">Collaboration Project,</a><a class="link-muted" rel="tag" href="/tags/Eletromagnetic-B%E6%B5%8B/">Eletromagnetic B测 </a></div><a class="article-more button is-small is-size-7" href="/collaboration/%E8%A5%BF%E7%94%B5B%E6%B5%8B%E8%AE%A1%E7%BD%91%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/knowledge/GANs/">The Basic Principles and Some Further Discussion of GANs</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-04-02T02:48:20.000Z" title="2024-04-02T02:48:20.000Z">2024-04-02</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-04-02T09:27:57.579Z" title="2024-04-02T09:27:57.579Z">2024-04-02</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/knowledge/">knowledge</a></span><span class="level-item"><i class="far fa-clock"></i> 5 minutes read (About 804 words)</span></div></div><div class="content">This is a post about the basic principles and some further discussion of GANs.</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Professional-Knowledge/">Professional Knowledge </a></div><a class="article-more button is-small is-size-7" href="/knowledge/GANs/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/blog/CommonScreenCommands/">Common Screen Commands</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-03-05T08:37:26.000Z" title="2024-03-05T08:37:26.000Z">2024-03-05</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-03-05T08:41:51.729Z" title="2024-03-05T08:41:51.729Z">2024-03-05</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/blog/">blog</a></span><span class="level-item"><i class="far fa-clock"></i> a minute read (About 168 words)</span></div></div><div class="content">This is a brief introduction about the common commands of the Screen utility on the Linux terminal.</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Project-Tools/">Project Tools </a></div><a class="article-more button is-small is-size-7" href="/blog/CommonScreenCommands/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/blog/SSHPrivateKey/">Connect the Linux Server By Private Key in WinSCP Software</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-02-09T13:06:25.000Z" title="2024-02-09T13:06:25.000Z">2024-02-09</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-02-09T14:13:56.803Z" title="2024-02-09T14:13:56.803Z">2024-02-09</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/blog/">blog</a></span><span class="level-item"><i class="far fa-clock"></i> 3 minutes read (About 392 words)</span></div></div><div class="content">This post tells how to connect the linux server when we only get the permission generated by public key .</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Project-Tools/">Project Tools </a></div><a class="article-more button is-small is-size-7" href="/blog/SSHPrivateKey/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/blog/AnacondaOnLinuxServer/">Install Anaconda On the Linux Server</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-02-06T14:48:04.000Z" title="2024-02-06T14:48:04.000Z">2024-02-06</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-02-08T07:42:05.864Z" title="2024-02-08T07:42:05.864Z">2024-02-08</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/blog/">blog</a></span><span class="level-item"><i class="far fa-clock"></i> 2 minutes read (About 309 words)</span></div></div><div class="content">This is a brief introduction about how to install the anaconda on the linux server.</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Project-Tools/">Project Tools </a></div><a class="article-more button is-small is-size-7" href="/blog/AnacondaOnLinuxServer/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/blog/GraphPlotTool/">A Graph Plot Tool that Integrates Data Processing And Visualization</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-01-31T15:15:27.000Z" title="2024-01-31T15:15:27.000Z">2024-01-31</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-01-31T15:48:29.542Z" title="2024-01-31T15:48:29.542Z">2024-01-31</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/blog/">blog</a></span><span class="level-item"><i class="far fa-clock"></i> 15 minutes read (About 2286 words)</span></div></div><div class="content">I developed a useful graph plot tool that integrates data processing and visualization by the format of python class.</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Data-Visualization/">Data Visualization </a></div><a class="article-more button is-small is-size-7" href="/blog/GraphPlotTool/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal"><a class="has-link-black-ter" href="/blog/GeneticAlgorithm/">Genetic Algorithm</a></h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-01-28T12:26:16.000Z" title="2024-01-28T12:26:16.000Z">2024-01-28</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-01-29T16:11:23.730Z" title="2024-01-29T16:11:23.730Z">2024-01-30</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/blog/">blog</a></span><span class="level-item"><i class="far fa-clock"></i> 15 minutes read (About 2313 words)</span></div></div><div class="content">关于遗传算法的原理推导与实际应用。</div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Mathematical-Modeling/">Mathematical Modeling </a></div><a class="article-more button is-small is-size-7" href="/blog/GeneticAlgorithm/#more"><i class="fas fa-book-reader has-text-grey"></i>  Read more</a></div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/default-index/page/0/">Previous</a></div><div class="pagination-next"><a href="/default-index/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/default-index/">1</a></li><li><a class="pagination-link" href="/default-index/page/2/">2</a></li><li><a class="pagination-link" href="/default-index/page/3/">3</a></li><li><a class="pagination-link" href="/default-index/page/4/">4</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-96x96 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.jpg" alt="Jiawei Hu"></figure><p class="title is-size-4 is-block" style="line-height: 'inherit'; font-family: Times New Roman">Jiawei Hu</p><p style="white-space: pre-line; font-style: italic; font-family: Times New Roman; margin-bottom: 0.50rem; font-size: 1.0em">Computer Science
Machine Learning
</p><p class="is-size-5 is-flex justify-content-center" style="font-family: Times New Roman"><i class="fas fa-map-marker-alt mr-1"></i><span>Xidian University, China</span></p></div></div></nav><nav class="level menu-list is-mobile" style="margin-bottom:1rem"><a class="level-item has-text-centered is-marginless" href="/archives"><div><p class="heading">Posts</p><div><p class="title">34</p></div></div></a><a class="level-item has-text-centered is-marginless" href="/categories"><div><p class="heading">Categories</p><div><p class="title">6</p></div></div></a><a class="level-item has-text-centered is-marginless" href="/tags"><div><p class="heading">Tags</p><div><p class="title">23</p></div></div></a></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/JiaweiHu-XDU" target="_blank" rel="noopener"><i class="fab fa-github"></i>  Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/JiaweiHu-XDU"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:jiaweihu_xdu@163.com"><i class="fa-solid fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="QQ" href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=1444980878&amp;website=www.oicqzone.com"><i class="fab fa-qq"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/blog/"><span class="level-start"><span class="level-item">blog</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/collaboration/"><span class="level-start"><span class="level-item">collaboration</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/knowledge/"><span class="level-start"><span class="level-item">knowledge</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/life/"><span class="level-start"><span class="level-item">life</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/projects/"><span class="level-start"><span class="level-item">projects</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/readings/"><span class="level-start"><span class="level-item">readings</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li></ul></div></div></div><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">follow.it</h3><form action="" method="post" target="_blank"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-09-02T06:42:35.340Z">2024-09-02</time></p><p class="title"><a href="/collaboration/Learning&amp;Planning/">Learning &amp; Planning</a></p><p class="categories"><a href="/collaboration/">collaboration</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-05-26T05:35:35.354Z">2024-05-26</time></p><p class="title"><a href="/collaboration/soc%E5%A4%8D%E4%B9%A0/">SOC微体系结构设计</a></p><p class="categories"><a href="/collaboration/">collaboration</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-05-02T05:15:09.637Z">2024-05-02</time></p><p class="title"><a href="/blog/Typora%E5%B8%B8%E7%94%A8%E8%AF%AD%E6%B3%95%E6%95%B4%E7%90%86/">Common syntax for Typroa</a></p><p class="categories"><a href="/blog/">blog</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-27T15:49:40.732Z">2024-04-27</time></p><p class="title"><a href="/collaboration/%E8%A5%BF%E7%94%B5B%E6%B5%8B%E8%AE%A1%E7%BD%91%E7%BB%BC%E5%90%88%E5%AE%9E%E9%AA%8C/">西电计科B测——计算机网络综合实验</a></p><p class="categories"><a href="/collaboration/">collaboration</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2024-04-02T02:48:20.000Z">2024-04-02</time></p><p class="title"><a href="/knowledge/GANs/">The Basic Principles and Some Further Discussion of GANs</a></p><p class="categories"><a href="/knowledge/">knowledge</a></p></div></article></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2024/"><span class="level-start"><span class="level-item">2024</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/archives/2023/"><span class="level-start"><span class="level-item">2023</span></span><span class="level-end"><span class="level-item tag">23</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Collaboration-Project/"><span class="tag">Collaboration Project</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/College-Life/"><span class="tag">College Life</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-Network/"><span class="tag">Computer Network</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-Principle/"><span class="tag">Computer Principle</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-Vision/"><span class="tag">Computer Vision</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Visualization/"><span class="tag">Data Visualization</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-Reinforcement-Learning/"><span class="tag">Deep Reinforcement Learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Eletromagnetic-B%E6%B5%8B/"><span class="tag">Eletromagnetic B测</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Eletromagnetic-Physics/"><span class="tag">Eletromagnetic Physics</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embedded-System/"><span class="tag">Embedded System</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Health/"><span class="tag">Health</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Life-Knowledge/"><span class="tag">Life Knowledge</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Life-Wisdom/"><span class="tag">Life Wisdom</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Literature-Survey/"><span class="tag">Literature Survey</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mathematical-Modeling/"><span class="tag">Mathematical Modeling</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Microcomputer/"><span class="tag">Microcomputer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenSSL/"><span class="tag">OpenSSL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Professional-Knowledge/"><span class="tag">Professional Knowledge</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Project-Tools/"><span class="tag">Project Tools</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reinforcement-Learning/"><span class="tag">Reinforcement Learning</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Jiawei Hu - Jiawei Hu&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2023-2024 Jiawei Hu</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv"><span id="busuanzi_container_site_uv">Site UV: <span id="busuanzi_value_site_uv"></span></span>   <span id="busuanzi_container_site_pv">Site PV: <span id="busuanzi_value_site_pv"></span></span></span></p><p class="is-size-7"> </p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/jiaweiHu-XDU/jiaweiHu-XDU.github.io"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><script src="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/katex.min.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/katex.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/contrib/auto-render.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><script src="/js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><div id="dark" onclick="switchDarkMode()"></div><script type="text/javascript" src="/js/universe.js"></script></body></html>