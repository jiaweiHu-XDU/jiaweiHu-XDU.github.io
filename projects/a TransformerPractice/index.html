<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Transformer Concept Exploration and Practice in Pytorch - Jiawei Hu - Jiawei Hu&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="theme-color" content="#3273dc"><meta name="application-name" content="Jiawei Hu - Jiawei Hu&#039;s Blog"><meta name="msapplication-TileImage" content="/img/logo.png"><meta name="msapplication-TileColor" content="#3273dc"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Jiawei Hu - Jiawei Hu&#039;s Blog"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="This post explores the principles about the impressive transformer structure and for downstream tasks, such as machine translate, it achieves the full implementation and training details."><meta property="og:type" content="blog"><meta property="og:title" content="Transformer Concept Exploration and Practice in Pytorch"><meta property="og:url" content="https://jiaweihu-xdu.github.io/projects/a%20TransformerPractice/"><meta property="og:site_name" content="Jiawei Hu - Jiawei Hu&#039;s Blog"><meta property="og:description" content="This post explores the principles about the impressive transformer structure and for downstream tasks, such as machine translate, it achieves the full implementation and training details."><meta property="og:locale" content="en_US"><meta property="og:image" content="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/projects/ConceptPlot.drawio.svg"><meta property="og:image" content="https://jiaweihu-xdu.github.io/projects/a%20TransformerPractice/ConceptPlot.drawio.svg"><meta property="og:image" content="https://jiaweihu-xdu.github.io/projects/a%20TransformerPractice/ConceptPlot.drawio.svg"><meta property="og:image" content="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118114521.png"><meta property="og:image" content="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118114756.png"><meta property="og:image" content="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118114852.png"><meta property="og:image" content="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118114928.png"><meta property="og:image" content="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118134352.png"><meta property="og:image" content="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118143922.png"><meta property="og:image" content="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118145855.png"><meta property="og:image" content="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118200337.png"><meta property="article:published_time" content="2024-11-29T08:18:29.127Z"><meta property="article:modified_time" content="2024-11-29T08:23:19.031Z"><meta property="article:author" content="Jiawei Hu"><meta property="article:tag" content="Transformer"><meta property="article:tag" content="NLP"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/projects/ConceptPlot.drawio.svg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://jiaweihu-xdu.github.io/projects/a%20TransformerPractice/"},"headline":"Transformer Concept Exploration and Practice in Pytorch","image":["https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118114521.png","https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118114756.png","https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118114852.png","https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118114928.png","https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118134352.png","https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118143922.png","https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118145855.png","https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118200337.png"],"datePublished":"2024-11-29T08:18:29.127Z","dateModified":"2024-11-29T08:23:19.031Z","author":{"@type":"Person","name":"Jiawei Hu"},"publisher":{"@type":"Organization","name":"Jiawei Hu - Jiawei Hu's Blog","logo":{"@type":"ImageObject","url":"https://jiaweihu-xdu.github.io/img/logo.png"}},"description":"This post explores the principles about the impressive transformer structure and for downstream tasks, such as machine translate, it achieves the full implementation and training details."}</script><link rel="canonical" href="https://jiaweihu-xdu.github.io/projects/a%20TransformerPractice/"><link rel="icon" href="/img/logo.png"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/6.0.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/css/justifiedGallery.min.css"><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js"></script><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const id = '#' + CSS.escape(location.hash.substring(1));
          const $tabMenu = document.querySelector(`.tabs a[href="${id}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(id);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"></head><body class="is-3-column"><canvas id="universe"></canvas><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="Jiawei Hu - Jiawei Hu&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">JIAWEI HU&#039;S LOG BOOK</a><a class="navbar-item" href="/blog">BLOG</a><a class="navbar-item" href="/knowledge">KNOWLEDGE</a><a class="navbar-item" href="/publications">PUBLICATIONS</a><a class="navbar-item" href="/projects">PROJECTS</a><a class="navbar-item" href="/life">LIFE</a><a class="navbar-item" href="/readings">READINGS</a><a class="navbar-item" href="/collaboration">COLLABORATION</a><a class="navbar-item" href="/archives">ARCHIVES</a><a class="navbar-item" href="/categories">CATEGORIES</a><a class="navbar-item" href="/tags">TAGS</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="GitHub" href="https://github.com/jiaweiHu-XDU/jiaweiHu-XDU.github.io"><i class="fab fa-github"></i></a><a class="navbar-item" target="_blank" rel="noopener" title="Gitee" href="https://gitee.com/hujiawe_i"><i class="fa-brands fa-gofore"></i></a><a class="navbar-item night" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-9-widescreen"><div class="card"><article class="card-content article" role="article"><h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">Transformer Concept Exploration and Practice in Pytorch</h1><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><i class="far fa-calendar-alt"> </i><time dateTime="2024-11-29T08:18:29.127Z" title="2024-11-29T08:18:29.127Z">2024-11-29</time></span><span class="level-item is-hidden-mobile"><i class="far fa-calendar-check"> </i><time dateTime="2024-11-29T08:23:19.031Z" title="2024-11-29T08:23:19.031Z">2024-11-29</time></span><span class="level-item"><i class="far fa-folder-open has-text-grey"></i> <a class="link-muted" href="/projects/">projects</a></span><span class="level-item"><i class="far fa-clock"></i> an hour read (About 6794 words)</span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;<span id="busuanzi_value_page_pv">0</span>&nbsp;visits</span></div></div><div class="content"><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>Transformer 是一种广泛应用与自然语言处理的神经网络架构，它基于自注意力机制，允许模型在做出预测时为句子中的不同单词赋予不同的重要性。它非常擅长处理序列任务，并且具有并行计算的优势，因此在大规模数据集上训练时非常高效。序列任务是任何将输入序列进行变换得到输出序列的任务，例如 machine translation, text summarization, and question answering. 而这种序列模型往往具有编码-解码的模型架构，Transformer 亦是如此：<strong>编码器将输入的符号序列映射为提取的连续特征表示，而解码器负责一次生成一个符号，并在每一步将之前生成的符号再次添加到输入以此生成下一个符号，又称为自回归模型。</strong> 这种依赖于过去和当前的输入的任务，也被称为<strong>因果语言建模</strong> (causal language modeling)。</p>
<p>在这篇文章中，实现了对 Transformer 结构的学习以及在机器翻译任务上用Pytorch全流程实现Transformer。</p>
<h2 id="Understanding-of-Theories"><a href="#Understanding-of-Theories" class="headerlink" title="Understanding of Theories"></a>Understanding of Theories</h2><h3 id="Tokenizer-amp-Embedding"><a href="#Tokenizer-amp-Embedding" class="headerlink" title="Tokenizer &amp; Embedding"></a>Tokenizer &amp; Embedding</h3><p>我们需要从原点出发理解整个处理过程，给定一个自然语言序列，需要做的工作包括对自然语言序列进行分词以及词嵌入，能够将自然语言的单词转换为Transformer模型需要处理的向量化表示。如下图所示，自然语言单词通过语法规则构造出规范的语句，而自然语句通过分词器将语句分级为 tokens，有时候为了处理方便，也会将自然语言单词进行拆分构成不同的token，这取决于分词器的实现。</p>
<p>分词后的tokens序列主要用来构造模型学习的语料库，而词嵌入 embedding 则是将tokens序列转换为连续的向量表示 embeddings，以便模型能够处理整个语句。经过这种变换后，自然语言单词能够转换为浮点数构成的数值向量，这不仅考虑了token的特异性，而且数值能够表示不同token之前的联系，即语境信息。</p>
<p>这种处理方式使得模型能够处理人类的自然语言，并且能够捕捉到不同单词之间的语义关系。</p>
<img src="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/projects/ConceptPlot.drawio.svg" alt="Convert Pipline" width="70%"/>

<p><img src="ConceptPlot.drawio.svg" alt="ConceptPlot.drawio"></p>
<p><img src="ConceptPlot.drawio.svg" alt="ConceptPlot.drawio"></p>
<p>在数据管理器中，基于 <code>torchtext</code> 实现了用于文本分词的 <code>tokenizer</code> 以及对应的 Vocabulary.</p>
<p>整体的流程是，通过预训练的 tokenizer 将输入的文本进行分词，并将单个 token 输出为 token_id，进一步通过输入的语料库来构建词汇表，在词汇表中可以通过 token_id 查找对应的 embedding，这是作为单词在句子中特殊语义的标记。</p>
<p>一些特殊的 token 标记：</p>
<ul>
<li><code>PAD_IDX</code>：由于在一个 batch 中不同的语句所转换后的 tokens 长度不一，为了能够统一转换为矩阵，需要对这些语句进行对齐，可以理解为以最长的 tokens 序列为标准，以一个特殊的标记填充其他语句。</li>
<li><code>EOS_IDX</code>: 有填充就必定要有语句结束标记，指定一个语句在哪个位置已经结束。</li>
<li><code>BOS_IDX</code>: 标记句子的开始，一般是以该 token 为解码器输入，然后逐渐生成我们想要的其他 tokens，所以可以认为这是解码器的特殊启动标记。</li>
</ul>
<figure class="highlight python"><figcaption><span>Data Manager</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> Counter</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch.nn.utils.rnn <span class="keyword">import</span> pad_sequence</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">import</span> torchtext</span><br><span class="line">torchtext.disable_torchtext_deprecation_warning()</span><br><span class="line"><span class="keyword">from</span> torchtext.data.utils <span class="keyword">import</span> get_tokenizer</span><br><span class="line"><span class="keyword">from</span> torchtext.vocab <span class="keyword">import</span> vocab</span><br><span class="line"><span class="keyword">from</span> torchtext.utils <span class="keyword">import</span> extract_archive</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DataManeger</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    A integrated data manager with builded tokenizer and vocabulary.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, src_mode, tgt_mode, data_path</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            src_mode: source natural language, (&#x27;en&#x27;: English, &#x27;de&#x27;: Deutsch / German&#x27;, &#x27;cs&#x27;: Čeština / Czech, &#x27;fr&#x27;: Français / French).</span></span><br><span class="line"><span class="string">            tgt_mode: target natural language, (&#x27;en&#x27;: English, &#x27;de&#x27;: Deutsch / German&#x27;, &#x27;cs&#x27;: Čeština / Czech, &#x27;fr&#x27;: Français / French).</span></span><br><span class="line"><span class="string">            data_path: the path of dataset.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.src_mode = src_mode</span><br><span class="line">        self.tgt_mode = tgt_mode</span><br><span class="line"></span><br><span class="line">        self.tokenize_src = get_tokenizer(<span class="string">&#x27;spacy&#x27;</span>, language=src_mode)</span><br><span class="line">        self.tokenize_tgt = get_tokenizer(<span class="string">&#x27;spacy&#x27;</span>, language=tgt_mode)</span><br><span class="line"></span><br><span class="line">        train_urls = (<span class="string">&#x27;train.&#x27;</span>+ src_mode +<span class="string">&#x27;.gz&#x27;</span>, <span class="string">&#x27;train.&#x27;</span>+ tgt_mode +<span class="string">&#x27;.gz&#x27;</span>)</span><br><span class="line">        val_urls = (<span class="string">&#x27;val.&#x27;</span>+ src_mode +<span class="string">&#x27;.gz&#x27;</span>, <span class="string">&#x27;val.&#x27;</span>+ tgt_mode +<span class="string">&#x27;.gz&#x27;</span>)</span><br><span class="line">        test_urls = (<span class="string">&#x27;test_2016_flickr.&#x27;</span>+ src_mode +<span class="string">&#x27;.gz&#x27;</span>, <span class="string">&#x27;test_2016_flickr.&#x27;</span>+ tgt_mode +<span class="string">&#x27;.gz&#x27;</span>)</span><br><span class="line"></span><br><span class="line">        self.train_filepaths = [extract_archive(data_path + url)[<span class="number">0</span>] <span class="keyword">for</span> url <span class="keyword">in</span> train_urls]</span><br><span class="line">        self.val_filepaths = [extract_archive(data_path + url)[<span class="number">0</span>] <span class="keyword">for</span> url <span class="keyword">in</span> val_urls]</span><br><span class="line">        self.test_filepaths = [extract_archive(data_path + url)[<span class="number">0</span>] <span class="keyword">for</span> url <span class="keyword">in</span> test_urls]</span><br><span class="line"></span><br><span class="line">        self.src_vocab = self.build_vocab(self.tokenize_src, self.train_filepaths[<span class="number">0</span>])</span><br><span class="line">        self.tgt_vocab = self.build_vocab(self.tokenize_tgt, self.train_filepaths[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        self.src_vocab.set_default_index(self.src_vocab[<span class="string">&#x27;&lt;unk&gt;&#x27;</span>])</span><br><span class="line">        self.tgt_vocab.set_default_index(self.tgt_vocab[<span class="string">&#x27;&lt;unk&gt;&#x27;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">make_dataset</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Process out the data through their zip files.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        train_data = self.data_process(self.train_filepaths)</span><br><span class="line">        val_data = self.data_process(self.val_filepaths)</span><br><span class="line">        test_data = self.data_process(self.test_filepaths)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> train_data, val_data, test_data</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">build_vocab</span>(<span class="params">self, tokenizer, train_filepath</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Build the corresponding vocabulary for the two languages.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        counter = Counter()</span><br><span class="line">        <span class="keyword">with</span> io.<span class="built_in">open</span>(train_filepath, encoding=<span class="string">&quot;utf8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            <span class="keyword">for</span> string_ <span class="keyword">in</span> f:</span><br><span class="line">                counter.update(tokenizer(string_))</span><br><span class="line">        <span class="keyword">return</span> vocab(counter, specials=[<span class="string">&#x27;&lt;unk&gt;&#x27;</span>, <span class="string">&#x27;&lt;pad&gt;&#x27;</span>, <span class="string">&#x27;&lt;bos&gt;&#x27;</span>, <span class="string">&#x27;&lt;eos&gt;&#x27;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">data_process</span>(<span class="params">self, filepaths</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Create the input_id tensors using tokenizer and vocabulary.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        raw_src_iter = <span class="built_in">iter</span>(io.<span class="built_in">open</span>(filepaths[<span class="number">0</span>], encoding=<span class="string">&quot;utf8&quot;</span>))</span><br><span class="line">        raw_tgt_iter = <span class="built_in">iter</span>(io.<span class="built_in">open</span>(filepaths[<span class="number">1</span>], encoding=<span class="string">&quot;utf8&quot;</span>))</span><br><span class="line">        data = []</span><br><span class="line">        <span class="keyword">for</span> (raw_src, raw_tgt) <span class="keyword">in</span> <span class="built_in">zip</span>(raw_src_iter, raw_tgt_iter):</span><br><span class="line">            src_tensor = torch.tensor([self.src_vocab[token] <span class="keyword">for</span> token <span class="keyword">in</span> self.tokenize_src(raw_src)],</span><br><span class="line">                                    dtype=torch.long)</span><br><span class="line">            tgt_tensor = torch.tensor([self.tgt_vocab[token] <span class="keyword">for</span> token <span class="keyword">in</span> self.tokenize_tgt(raw_tgt)],</span><br><span class="line">                                    dtype=torch.long)</span><br><span class="line">            data.append((src_tensor, tgt_tensor))</span><br><span class="line">        <span class="keyword">return</span> data</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">make_iter</span>(<span class="params">self, train, validate, test, batch_size</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Create the iterater for sub-dataset using collection function.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        train_iter = DataLoader(train, batch_size=batch_size,</span><br><span class="line">                                shuffle=<span class="literal">True</span>, collate_fn=self.generate_batch)</span><br><span class="line">        valid_iter = DataLoader(validate, batch_size=batch_size,</span><br><span class="line">                                shuffle=<span class="literal">False</span>, collate_fn=self.generate_batch)</span><br><span class="line">        test_iter = DataLoader(test, batch_size=batch_size,</span><br><span class="line">                            shuffle=<span class="literal">False</span>, collate_fn=self.generate_batch)</span><br><span class="line">        <span class="keyword">return</span> train_iter, valid_iter, test_iter</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">generate_batch</span>(<span class="params">self, data_batch</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Construct the batch input_id tensors, add the bos and eos tokens and padding the sentence.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        SRC_PAD_IDX, TGT_PAD_IDX = self.src_vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>], self.tgt_vocab[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>]</span><br><span class="line">        SRC_BOS_IDX, TGT_BOS_IDX = self.src_vocab[<span class="string">&#x27;&lt;bos&gt;&#x27;</span>], self.tgt_vocab[<span class="string">&#x27;&lt;bos&gt;&#x27;</span>]</span><br><span class="line">        SRC_EOS_IDX, TGT_EOS_IDX = self.src_vocab[<span class="string">&#x27;&lt;eos&gt;&#x27;</span>], self.tgt_vocab[<span class="string">&#x27;&lt;eos&gt;&#x27;</span>]</span><br><span class="line">        src_batch, tgt_batch = [], []</span><br><span class="line">        <span class="keyword">for</span> (src_item, tgt_item) <span class="keyword">in</span> data_batch:</span><br><span class="line">            src_batch.append(torch.cat([torch.tensor([SRC_BOS_IDX]), src_item, torch.tensor([SRC_EOS_IDX])], dim=<span class="number">0</span>))</span><br><span class="line">            tgt_batch.append(torch.cat([torch.tensor([TGT_BOS_IDX]), tgt_item, torch.tensor([TGT_EOS_IDX])], dim=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line">        <span class="comment"># padding the sentence using PAD_IDX</span></span><br><span class="line">        src_batch = pad_sequence(src_batch, padding_value=SRC_PAD_IDX)</span><br><span class="line">        tgt_batch = pad_sequence(tgt_batch, padding_value=TGT_PAD_IDX)</span><br><span class="line">        <span class="keyword">return</span> src_batch.t(), tgt_batch.t()</span><br></pre></td></tr></table></figure>

<h3 id="Position-Embedding"><a href="#Position-Embedding" class="headerlink" title="Position Embedding"></a>Position Embedding</h3><ul>
<li>并行处理</li>
</ul>
<p>其实可以发现，transformer 是并行处理一个语句中的所有 tokens，因为它同时接受这些 tokens 作为输入，接着直接计算注意力分数。</p>
<ul>
<li>位置信息</li>
</ul>
<blockquote>
<p>不同的 token 在语句的不同位置是语法体现，因此需要明确位置信息。</p>
</blockquote>
<p>因此仅仅是单个 token 的嵌入向量，并不能表示在语句中的位置关系，这就需要额外引入能够表示 token 在语句中的位置信息。而位置信息需要满足的要求有如下两点，</p>
<ol>
<li>It should be the same for a position irrespective of the token in that position. So while the sequence might change, the positional embeddings must stay the same. [1]</li>
<li>They should not be too large, or otherwise they will dominate semantic similarity. [1]</li>
</ol>
<ul>
<li>函数选取<br>Position Embedding 不能够太大以免破坏 token 本身的语义信息。因此对于非周期函数例如线性函数，因为值域是无限的，并不容易控制随着维度增大引起的值域增大。</li>
</ul>
<p>较好的选择就是正余弦函数，它们的值域都缩放在 [-1, 1] 之间，连续且具有周期性。相比于 <em>sigmoid</em> 函数对较大的数基本已经保持平稳，三角函数能够对较大的数具有较大变换幅度，这对于处理长序列是非常有用的。</p>
<p>为了避免三角函数对于不同位置重复相同的结果，给定三角函数一个较低的频率，即具有较大的周期，这将对于最长的序列长度也不会不断重复。频率低就意味着相邻位置变化幅度比较小，这也不是我们想要的，因此对位置编码的奇数维度叠加低频 <em>sine</em> 函数，而对偶数维度叠加低频 <em>cosine</em> 函数。</p>
<p>对于一个单词的嵌入向量：<code>torch.size([1, 512])</code>，其中 512 嵌入向量的奇数位置采用低频 <em>sine</em> 函数，偶数位置采用低频 <em>cosine</em> 函数，这样能够保证每个单词的嵌入向量都包含位置信息。</p>
<p>$$<br>\begin{aligned}<br>PE(pos, 2i) &amp;= \sin(\frac{pos}{1000^{2i/d_{model}}})\newline<br>PE(pos, 2i+1)&amp; = \cos(\frac{pos}{1000^{2i/d_{model}}})<br>\end{aligned}<br>$$</p>
<img src="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118114521.png" alt="pos=28 时对应的嵌入向量位置编码表示" width="40%"/>

<p>从上图可以看到，这种交叉位置编码平衡了单独两个余弦函数的特性，能够在相邻位置保持变化性，并且对于长序列的位置编码也不会出现大量重复值。</p>
<img src="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118114756.png" alt="dim=512 时交叉位置编码表示" width="40%"/>

<img src="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118114852.png" alt="dim=512 时正弦位置编码表示" width="40%"/>

<img src="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118114928.png" alt="dim=512 时余弦位置编码表示" width="40%"/>

<p>对比交叉、正弦以及余弦位置编码可以看出，交叉位置编码在不同维度是不断变化的，而单独的正弦和余弦函数都出现了较为平滑的区域，即变换幅度都基本不变。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PositionalEncoding</span>(nn.Module):</span><br><span class="line">    <span class="comment"># Implement the position encoding (PE) function.</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, dropout, max_len=<span class="number">5000</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(PositionalEncoding, self).__init__()</span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute the positional encodings once in log space.</span></span><br><span class="line">        pe = torch.zeros(max_len, d_model)</span><br><span class="line">        position = torch.arange(<span class="number">0</span>, max_len).unsqueeze(<span class="number">1</span>)</span><br><span class="line">        div_term = torch.exp(</span><br><span class="line">            torch.arange(<span class="number">0</span>, d_model, <span class="number">2</span>) * -(math.log(<span class="number">10000.0</span>) / d_model)</span><br><span class="line">        )</span><br><span class="line">        pe[:, <span class="number">0</span>::<span class="number">2</span>] = torch.sin(position * div_term)</span><br><span class="line">        pe[:, <span class="number">1</span>::<span class="number">2</span>] = torch.cos(position * div_term)</span><br><span class="line">        pe = pe.unsqueeze(<span class="number">0</span>)</span><br><span class="line">        self.register_buffer(<span class="string">&quot;pe&quot;</span>, pe)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># adds token embedding to its position embedding</span></span><br><span class="line">        x = x + self.pe[:, : x.size(<span class="number">1</span>)].requires_grad_(<span class="literal">False</span>)</span><br><span class="line">        <span class="keyword">return</span> self.dropout(x)</span><br></pre></td></tr></table></figure>

<h3 id="Encoder"><a href="#Encoder" class="headerlink" title="Encoder"></a>Encoder</h3><p>编码器负责从输入的 token 序列中提取出语义特征，其结构如下图所示：</p>
<div style="display: flex; align-items: center; gap: 40px;">
  <img src="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118134352.png" style="flex: 1; width: 100%;" >
  <div>
    <h3>Residual Connection</h3>
    <p>
      残差连接是将该层的输入向量直接传递到输出而不做任何处理，并将其加到该层处理后得到的输出向量上面。这是一项简单高效的技术用于处理深度神经网络梯度消失的问题，以 ResNet 网络之名提出.
    </p>
    <h3>Layer Normalization</h3>
    <p>
      层归一化是在每层中对所有样本的输出进行规范化，而不是对每个批次进行规范化。如下图中对比，Layer Norm 对于单个样本的所有特征进行规范化，使得层内神经元输出的分布具有稳定的均值和方差。
    </p>
    <p>
      在 Transformer 中是对每个 token 形成的 embedding 进行规范化，而不是对整个序列进行规范化。
      然后使用可学习的参数（如 $\beta$ 和$\gamma$）对归一化后的输出进行缩放和平移。这样既可以保持数据的分布稳定性，又可以保留一定的灵活性。形式化的表示为：
      $$
      \text{LN}(x) = \frac{x - \mu}{\sigma + \epsilon} \cdot \gamma + \beta
      $$
      其中，$x$ 是输入向量，$\mu$ 和 $\sigma$ 是输入向量的均值和标准差，$\epsilon$ 是一个很小的常数，用于防止除以零，$\gamma$ 和 $\beta$ 是可学习的参数。
    </p>
    <p>
    在 Transformer 中，对于层归一化可以放置在 Attention 层和前馈神经网络层之后，也可以放置在它们之后。最初的 Transformer 论文中，层归一化采取的是第一种方法，但被证明很难训练到梯度收敛，而第二种方法训练时变得更加稳定且收敛更快。[1]
    </p>
  </div>
</div>


<img src="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118143922.png" alt="Image source: Wu, Y., & He, K. (2018). Group normalization. ECCV" width="70%"/>

<figure class="highlight python"><figcaption><span>Layer Normalization</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">LayerNorm</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;Construct a layer norm module &quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, eps=<span class="number">1e-6</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(LayerNorm, self).__init__()</span><br><span class="line">        self.a_2 = nn.Parameter(torch.ones(d_model))</span><br><span class="line">        self.b_2 = nn.Parameter(torch.zeros(d_model))</span><br><span class="line">        self.eps = eps</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        mean = x.mean(-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        std = x.std(-<span class="number">1</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">        <span class="keyword">return</span> self.a_2 * (x - mean) / (std + self.eps) + self.b_2</span><br></pre></td></tr></table></figure>

<h3 id="Multi-Head-Attention"><a href="#Multi-Head-Attention" class="headerlink" title="Multi-Head Attention"></a>Multi-Head Attention</h3><p>多头注意力机制实际上是包含多个自注意力头的一种机制，每个头都独立地学习输入序列中的不同模式。多头注意力机制可以捕获更多的信息，并且可以更好地处理长距离依赖关系。多头注意力机制的结构如下图所示：</p>
<img src="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118145855.png" alt="Multi-Head Attention [1]" width="70%"/>

<p>其中，$d_{model}$ 是设定的每个 embedding 所包含的特征数量，实际上对于该超参数的设定，有时候并不清楚是否特征表示冗余（即浪费了很多特征块），或者是特征表示不足（即特征块不够）。</p>
<p>面对这样的问题，与其单独计算一个有着冗余风险的超大自注意力头，不如将这些所有特征分组成 $h$ 组，每组包含 $d_{model}/h$ 个特征，然后分别对每组进行自注意力计算，最后将所有组的输出拼接起来。这样能够保证每个子注意力头完成一个子任务，即捕获子模式：不同位置和不同特征的信息，从而更好地处理输入序列中的复杂关系。</p>
<h4 id="Self-Head-Attention"><a href="#Self-Head-Attention" class="headerlink" title="Self-Head Attention"></a>Self-Head Attention</h4><p>子注意力头主要是关注于序列本身中每个token与序列中其他token的依赖关系以及相似度，计算的注意力也成为：Scaled dot-product attention。</p>
<p>首先，将序列的嵌入特征表示投影成不同的三个向量，记为 query, key and value。然后计算注意力分数，通过测量 query 和 key 的点积来衡量 query 和 key 之间的相似度。这是因为点积可以衡量向量之间的相似性，如果非常接近则点积结果会有一个较大的值。一个有 $n$ 个 token 的序列来计算相互之间的相似度，即 Pairwise Similarity 将会得到 $n\times n$ 的注意力分数。</p>
<p>在获得注意力分数之后，因为点积结果是两个高维向量相乘并求和的结果，取值范围属于无限大，如果直接参与后续计算，势必会扰乱特征信息。因此，需要对注意力分数进行缩放，即除以 $\sqrt{d_k}$，其中 $d_k$ 是 key 的维度。然后通过 softmax 将其转换为注意力权重，这样做的目的是为了平衡不同维度之间的差异，使得计算结果更加稳定。</p>
<p>真正表示 token 语义的一直是 value 向量，通过构建的 query 和 key 只是获取 token 之间的注意力权重，然后对 value 向量中的每一个 token 进行加权求和，可以得到依赖于<strong>目前学习到的</strong> token 间语义关系的<strong>加权平均的</strong>嵌入特征表示。这里有两个特定词，希望给出一些个人的理解：</p>
<ul>
<li><p>目前学习到的<br>可以看到，对 query, key and value 的投影矩阵都是不断学习的参数，transformer 训练过程中，会不断通过学习调整 query, key 以提取更加准确的 token 间的语义依赖关系，这也会是 value 向量再次更新的关键，等到学习基本完毕时，我们可以任务，value 向量已经集成了之前所探寻得到的语义关系，代表了能够真正理解这句话的真实含义。</p>
</li>
<li><p>加权平均的<br>注意到注意力权重是通过 softmax 归一化的相似度分数，即对于注意力权重形如 $L\times L$，其中 $L$ 表示序列长度，每一行都表示对应的 token 与序列中其他 token 的语义关系（相似性），这样作用于 value 向量时，都会根据注意力分数提取其他相似的 token 的语义信息，从而得到一个加权平均的语义表示。</p>
</li>
</ul>
<p>因此更加具体的实现还是自注意力头，假设输入的嵌入向量表示为 $E\in R^{B\times L\times D}$，其中 $B$ 表示批次大小，$L$ 表示序列长度，$D$ 表示每个 token 被编码表示的向量长度，那么具体的计算过程如下：</p>
<p>$$<br>\begin{aligned}<br>\text{Q} &amp;= \text{W}_Q E \in R^{B\times L\times D} \newline<br>\text{K} &amp;= \text{W}_K E \in R^{B\times L\times D} \newline<br>\text{V} &amp;= \text{W}_V E \in R^{B\times L\times D} \newline<br>\text{Attention}(Q,K,V) &amp;= \text{softmax}\left(\frac{QK^T}{\sqrt{D}}\right)V<br>\end{aligned}<br>$$</p>
<p>当采用多头注意力机制后，还需要对拼接每个子注意力头得到的注意力分数进行线性变换，这是因为多头注意力机制不仅学习序列的注意力特征，而且学习每一个子注意力头对注意力分数的贡献程度，具体计算如下：<br>$$<br>\begin{aligned}<br>\text{MultiHead}(Q,K,V) &amp;= \text{Concat}(\text{head}_1, \text{head}_2, \ldots, \text{head}_h)W^O \newline<br>\text{where} \quad \text{head}_i &amp;= \text{Attention}(Q, K, V)<br>\end{aligned}<br>$$</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">attention</span>(<span class="params">query, key, value, mask=<span class="literal">None</span>, dropout=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;Compute &#x27;Scaled Dot Product Attention&#x27;&quot;</span></span><br><span class="line">    d_k = query.size(-<span class="number">1</span>)</span><br><span class="line">    scores = torch.matmul(query, key.transpose(-<span class="number">2</span>, -<span class="number">1</span>)) / math.sqrt(d_k)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> mask <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        scores = scores.masked_fill(mask == <span class="number">0</span>, -<span class="number">1e9</span>)</span><br><span class="line">    p_attn = scores.softmax(dim=-<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">if</span> dropout <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        p_attn = dropout(p_attn)</span><br><span class="line">    <span class="keyword">return</span> torch.matmul(p_attn, value), p_attn</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MultiHeadedAttention</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_head, d_model, dropout=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="comment"># Take in model size and number of heads.</span></span><br><span class="line">        </span><br><span class="line">        <span class="built_in">super</span>(MultiHeadedAttention, self).__init__()</span><br><span class="line">        <span class="keyword">assert</span> d_model % n_head == <span class="number">0</span></span><br><span class="line">        <span class="comment"># We assume d_v always equals d_k</span></span><br><span class="line">        self.d_k = d_model // n_head</span><br><span class="line">        self.n_head = n_head</span><br><span class="line">        self.linears = clones(nn.Linear(d_model, d_model), <span class="number">4</span>)</span><br><span class="line">        self.attn = <span class="literal">None</span></span><br><span class="line">        self.dropout = nn.Dropout(p=dropout)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, query, key, value, mask=<span class="literal">None</span></span>):</span><br><span class="line">        nbatches = query.size(<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Do all the linear projections in batch from d_model =&gt; n_head x d_k</span></span><br><span class="line">        query, key, value = [</span><br><span class="line">            lin(x).view(nbatches, -<span class="number">1</span>, self.n_head, self.d_k).transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">            <span class="keyword">for</span> lin, x <span class="keyword">in</span> <span class="built_in">zip</span>(self.linears, (query, key, value))</span><br><span class="line">        ]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Apply attention on all the projected vectors in batch.</span></span><br><span class="line">        x, self.attn = attention(</span><br><span class="line">            query, key, value, mask=mask, dropout=self.dropout</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Concat using a view and apply a final linear.</span></span><br><span class="line">        x = (</span><br><span class="line">            x.transpose(<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">            .contiguous()</span><br><span class="line">            .view(nbatches, -<span class="number">1</span>, self.n_head * self.d_k)</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> self.linears[-<span class="number">1</span>](x)</span><br></pre></td></tr></table></figure>
<h3 id="Feed-Forward-Network"><a href="#Feed-Forward-Network" class="headerlink" title="Feed-Forward Network"></a>Feed-Forward Network</h3><p>前馈神经网络就是一个简单的两层全连接层，通常第一层的隐藏层大小设置为 $4d_{model}$，并且使用 ReLU 作为激活函数，具体实现如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FeedForward</span>(nn.Module):</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, d_ff=<span class="number">2048</span>, dropout=<span class="number">0.1</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__() </span><br><span class="line">    </span><br><span class="line">        <span class="comment"># We set d_ff as a default to 2048</span></span><br><span class="line">        self.linear_1 = nn.Linear(d_model, d_ff)</span><br><span class="line">        self.dropout = nn.Dropout(dropout)</span><br><span class="line">        self.linear_2 = nn.Linear(d_ff, d_model)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.dropout(F.relu(self.linear_1(x)))</span><br><span class="line">        <span class="keyword">return</span> self.linear_2(x)</span><br></pre></td></tr></table></figure>

<h3 id="Decoder"><a href="#Decoder" class="headerlink" title="Decoder"></a>Decoder</h3><p>解码器的任务是不断地生成文本，还记得上文中提到的，<code>BOS_IDX</code> token 这个特殊的 token 标记句子的开始，可以先理解为解码器最开始输入的句子就是只有一个开始标记，然后不断地往下生成 $n$ 个单词，组成一句完整的话。但是对于 Transformer 而言，由于其强大的并行处理能力，实际上是通过对目标句子加阶梯型掩码（表示token生成的顺序），然后通过注意力机制不断得到一个加权平均的嵌入向量。实际上，这个嵌入向量表示就是 transformer 生成的目标句子，而且是一次性生成的。</p>
<img src="https://lzhms.oss-cn-hangzhou.aliyuncs.com/images/blog/blog/20241118200337.png" alt="Decoder Architecture [2]" width="50%"/>


<p>由于代码结果解释性比较强，为了深入地揭示 what happened 在 Decoder 中，下文主要结合代码执行结果进行说明。</p>
<ul>
<li><p>Decoder 输入的目标语句信息<br>从下面可以看到，目标语句长度 padding 到了 40 tokens 而且对应的每一个序列的第一个 token 都是 bos，说明在处理的时候 Decoder 还是以 bos 开始处理。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>target sentence length: <span class="number">40</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>target bos token <span class="built_in">id</span>: <span class="number">2</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>target eos token <span class="built_in">id</span>: <span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>target pad token <span class="built_in">id</span>: <span class="number">1</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>target first token <span class="built_in">id</span>:</span><br><span class="line"> tensor([<span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">        <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">        <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">        <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">        <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>,</span><br><span class="line">        <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">2</span>], device=<span class="string">&#x27;cuda:1&#x27;</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>target last token <span class="built_in">id</span>:</span><br><span class="line"> tensor([ <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,</span><br><span class="line">         <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>, <span class="number">15</span>,  <span class="number">1</span>,</span><br><span class="line">         <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,</span><br><span class="line">         <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,</span><br><span class="line">         <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,</span><br><span class="line">         <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,</span><br><span class="line">         <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,  <span class="number">1</span>,</span><br><span class="line">         <span class="number">1</span>,  <span class="number">1</span>], device=<span class="string">&#x27;cuda:1&#x27;</span>)</span><br></pre></td></tr></table></figure></li>
<li><p>Decoder 输入的 mask 信息<br>Decoder 需要考虑句子生成的先后顺序，在生成第 $i$ 个 token 的时候，只能看到第 $i$ 个 token 之前的 tokens，所以需要通过 mask 来实现，因此第一个 mask 记为 padding mask，第二个 mask 记为 subsequent mask，最后需要将这两个 mask 进行想与得到总的 mask，具体如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>target padding mask shape: torch.Size([<span class="number">128</span>, <span class="number">1</span>, <span class="number">40</span>, <span class="number">1</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>target padding mask:</span><br><span class="line">tensor([[[[ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  ..., <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  ..., <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  ..., <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        ...,</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  ..., <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  ..., <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[ <span class="literal">True</span>,  <span class="literal">True</span>,  <span class="literal">True</span>,  ..., <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>]]]], device=<span class="string">&#x27;cuda:1&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>target sub mask shape: torch.Size([<span class="number">40</span>, <span class="number">40</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>target sub mask:</span><br><span class="line">tensor([[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        ...,</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,  ..., <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,  ..., <span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>],</span><br><span class="line">        [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,  ..., <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]], device=<span class="string">&#x27;cuda:1&#x27;</span>, dtype=torch.uint8)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>target sentence mask shape:</span><br><span class="line">torch.Size([<span class="number">128</span>, <span class="number">1</span>, <span class="number">40</span>, <span class="number">40</span>])</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>target sentence mask:</span><br><span class="line">tensor([[[[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">          [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">          [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">          ...,</span><br><span class="line">          [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">          [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">          [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">          [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">          [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">          ...,</span><br><span class="line">          [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">          [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">          [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">          [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">          [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">          ...,</span><br><span class="line">          ...,</span><br><span class="line">          [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">          [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">          [<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>,  ..., <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]]]], device=<span class="string">&#x27;cuda:1&#x27;</span>, dtype=torch.uint8)</span><br></pre></td></tr></table></figure></li>
<li><p>Decoder Multi-Head Attention<br>解码器需要考虑两个序列，一是已经生成的序列（加掩码的目标序列），另一个是编码器提取的语义特征，这是为了进行两个序列的语义对齐，尤其是将 decoder attention 作为 query，encoder attention 作为 key、value。</p>
<ul>
<li><strong>直观的理解</strong><br>解码器向编码器提出一个查询请求，寻找下一个需要生成的 token，此时就需要比较解码器查询与编码器的特征表示的相似度，以此作为注意力分数，注意这个地方是不能在目标序列中得到下一个 token 的，因此 value 只能是编码器的 attention 输出，通过运算后这样会得到加权平均的语义特征，通过 projector 将这些语义特征投影到目标序列的词汇表中做一次分类，即可实现 token 的筛选。</li>
<li><strong>特征表示层面</strong><br>通过自注意力机制，解码器提取出的特征表示为 $L_1\times D$，编码器提取出的语义特征为 $L_2\times D$, 其中$ L_1, L_2$ 表示目标序列以及源序列的 token 长度，而 $D$ 表示每一个 token 的特征长度。实际上计算应为：<br>$$<br>\begin{aligned}<br>L_1\times D \cdot D\times L_2 &amp;= L_1\times L_2\newline<br>L_1\times L_2 \cdot L_2\times D &amp;= L_1\times D<br>\end{aligned}<br>$$<br>通过这种交叉注意力机制，解码器的每一个 token 都能够得到一个关于源序列各个 tokens 的表示关联程度的注意力权重，通过这个注意力权重与编码器提取出的语义特征，在 token 的没一个维度上进行加权求和，这样会得到相对于源序列的语义特征，这就是最后要生成的 tokens 序列。</li>
<li><strong>并行处理</strong><br>一次性生成整个句子？<br>其实深入地观察，可以发现，在解码器获取语义特征的过程中，施加了上面提到的掩码操作，这样就能够同时获得将要生成的 tokens 序列的位置关系，通过自注意力机制便一次性提取出所有 token 的语义特征，直接可以作为生成的 tokens 序列的特征。为了与源序列进行语义对齐，需要和编码器的语义特征计算相似度以获得源序列的注意力权重，再对源序列的语义特征进行加权平均。</li>
</ul>
</li>
</ul>
<figure class="highlight python"><figcaption><span>Decoder</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">DecoderLayer</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;Decoder is made of self-attn, src-attn, and feed forward (defined below)&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, n_head, d_model, d_ff, dropout</span>):</span><br><span class="line">        <span class="built_in">super</span>(DecoderLayer, self).__init__()</span><br><span class="line">        self.d_model = d_model</span><br><span class="line">        self.self_attn = MultiHeadedAttention(d_model=d_model, n_head=n_head)</span><br><span class="line">        self.cross_attn = MultiHeadedAttention(d_model=d_model, n_head=n_head)</span><br><span class="line">        self.feed_forward = FeedForward(d_model, d_ff, dropout)</span><br><span class="line">        <span class="comment"># 3 add &amp; norm sublayers one for self-attn, one for cross-attn and one for feed forward</span></span><br><span class="line">        self.sublayer = clones(SublayerConnection(d_model, dropout), <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, dec, enc, src_mask, tgt_mask</span>):</span><br><span class="line">        <span class="string">&quot;Compute self attention, cross attention, positionwise feed forward network..&quot;</span></span><br><span class="line"></span><br><span class="line">        dec = self.sublayer[<span class="number">0</span>](dec, <span class="keyword">lambda</span> dec: self.self_attn(dec, dec, dec, tgt_mask))</span><br><span class="line">        dec = self.sublayer[<span class="number">1</span>](dec, <span class="keyword">lambda</span> dec: self.cross_attn(dec, enc, enc, src_mask))</span><br><span class="line">        <span class="keyword">return</span> self.sublayer[<span class="number">2</span>](dec, self.feed_forward)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Decoder</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;Generic N layer decoder with masking.&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, dec_voc_size, max_len, n_layers, n_head, d_model, d_ff, dropout</span>):</span><br><span class="line">        <span class="built_in">super</span>(Decoder, self).__init__()</span><br><span class="line">        decoder_layer = DecoderLayer(n_head, d_model, d_ff, dropout)</span><br><span class="line">        self.layers = clones(decoder_layer, n_layers)</span><br><span class="line">        self.emb = Embedding(vocab_size=dec_voc_size,</span><br><span class="line">                            d_model=d_model,</span><br><span class="line">                            max_len=max_len,</span><br><span class="line">                            dropout=dropout)</span><br><span class="line"></span><br><span class="line">        self.norm = LayerNorm(decoder_layer.d_model)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, tgt, enc_src, src_mask, tgt_mask</span>):</span><br><span class="line">        tgt = self.emb(tgt)    <span class="comment"># embedded the input_ids</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> self.layers:</span><br><span class="line">            tgt = layer(tgt, enc_src, src_mask, tgt_mask)</span><br><span class="line">        <span class="keyword">return</span> self.norm(tgt)</span><br></pre></td></tr></table></figure>
<h3 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h3><p>在完成上述各模块的设计后，可以得到完整的 Transformer 模型，其结构如下：</p>
<figure class="highlight python"><figcaption><span>Transformer</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">from</span> torch.nn.functional <span class="keyword">import</span> log_softmax</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> model.encoder <span class="keyword">import</span> Encoder</span><br><span class="line"><span class="keyword">from</span> model.decoder <span class="keyword">import</span> Decoder</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Generator</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;Define standard linear + softmax generation step.&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, d_model, vocab</span>):</span><br><span class="line">        <span class="built_in">super</span>(Generator, self).__init__()</span><br><span class="line">        self.proj = nn.Linear(d_model, vocab)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="keyword">return</span> log_softmax(self.proj(x), dim=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Transformer</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    A standard Transformer architecture. Base for this and many</span></span><br><span class="line"><span class="string">    other models.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, src_pad_idx, tgt_pad_idx, tgt_bos_idx, enc_voc_size,</span></span><br><span class="line"><span class="params">                 dec_voc_size, d_model, n_head, max_len, d_ff, n_layers, dropout, device</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.src_pad_idx = src_pad_idx</span><br><span class="line">        self.tgt_pad_idx = tgt_pad_idx</span><br><span class="line">        self.tgt_bos_idx = tgt_bos_idx</span><br><span class="line">        self.device = device</span><br><span class="line">        self.encoder = Encoder(enc_voc_size=enc_voc_size,</span><br><span class="line">                            max_len=max_len,</span><br><span class="line">                            n_layers=n_layers,</span><br><span class="line">                            n_head=n_head,</span><br><span class="line">                            d_model=d_model,</span><br><span class="line">                            d_ff=d_ff,</span><br><span class="line">                            dropout=dropout)</span><br><span class="line">        self.decoder = Decoder(dec_voc_size=dec_voc_size,</span><br><span class="line">                            max_len=max_len,</span><br><span class="line">                            n_layers=n_layers,</span><br><span class="line">                            n_head=n_head,</span><br><span class="line">                            d_model=d_model,</span><br><span class="line">                            d_ff=d_ff,</span><br><span class="line">                            dropout=dropout)</span><br><span class="line"></span><br><span class="line">        self.generator = Generator(d_model, dec_voc_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, src, tgt</span>):</span><br><span class="line">        <span class="string">&quot;Take in and process masked src and target sequences.&quot;</span></span><br><span class="line">        src_mask = self.make_src_mask(src)</span><br><span class="line">        tgt_mask = self.make_tgt_mask(tgt)</span><br><span class="line">        enc_src = self.encoder(src, src_mask)</span><br><span class="line">        dec_tgt = self.decoder(tgt, enc_src, src_mask, tgt_mask)</span><br><span class="line">        <span class="keyword">return</span> self.generator(dec_tgt)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">make_src_mask</span>(<span class="params">self, src</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Mask the padding tokens int source sentence.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        src_mask = (src != self.src_pad_idx).unsqueeze(<span class="number">1</span>).unsqueeze(<span class="number">2</span>)</span><br><span class="line">        <span class="keyword">return</span> src_mask</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">make_tgt_mask</span>(<span class="params">self, tgt</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Mask the padding tokens int target sentence.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        tgt_pad_mask = (tgt != self.tgt_pad_idx).unsqueeze(<span class="number">1</span>).unsqueeze(<span class="number">3</span>)</span><br><span class="line">        tgt_len = tgt.shape[<span class="number">1</span>]</span><br><span class="line">        tgt_sub_mask = torch.tril(torch.ones(tgt_len, tgt_len)).<span class="built_in">type</span>(torch.ByteTensor).to(self.device)</span><br><span class="line">        tgt_mask = tgt_pad_mask &amp; tgt_sub_mask</span><br><span class="line">        <span class="keyword">return</span> tgt_mask</span><br></pre></td></tr></table></figure>

<h2 id="Exploration-From-Scratch"><a href="#Exploration-From-Scratch" class="headerlink" title="Exploration From Scratch"></a>Exploration From Scratch</h2><h3 id="Preparation"><a href="#Preparation" class="headerlink" title="Preparation"></a>Preparation</h3><h4 id="Clone-Project"><a href="#Clone-Project" class="headerlink" title="Clone Project"></a>Clone Project</h4><p>实操之前，需要将项目克隆下来，可以使用如下命令克隆到本地：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/jiaweiHu-XDU/a-TransformerPractice.git</span><br></pre></td></tr></table></figure>

<p>项目中已经集成好了所有必要的模型组件并通过不同的 Trainers 串联起来，以完成特定的下游任务。</p>
<h4 id="Install-Conda-Environment"><a href="#Install-Conda-Environment" class="headerlink" title="Install Conda Environment"></a>Install Conda Environment</h4><p>安装 conda 环境，tokenizer 使用最新的 spacy 库，其他库的版本也都是兼容下比较新的，可以通过以下命令进行环境配置：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda <span class="built_in">env</span> create -f environment.yml</span><br></pre></td></tr></table></figure>

<h4 id="Download-the-Dataset"><a href="#Download-the-Dataset" class="headerlink" title="Download the Dataset"></a>Download the Dataset</h4><p>本项目使用 <a target="_blank" rel="noopener" href="https://github.com/multi30k/dataset">Multi30K Dataset</a> 数据集训练和评估文本翻译模型，具体需要先在官网上下载数据集然后提取 <code>task1</code> 的所有文件，将其放置在目录 <code>data/multi30k</code> 下。详细目录结构可以见下文：</p>
<figure class="highlight python"><figcaption><span>Category Structure</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">.</span><br><span class="line">├─ data</span><br><span class="line">│  ├─ multi30k</span><br><span class="line">│  │  ├─ task1</span><br><span class="line">│  │  │  ├─ ...</span><br><span class="line">├─ dataset</span><br><span class="line">├─ model </span><br><span class="line">├─ output</span><br><span class="line">├─ trainer</span><br><span class="line">└─ model</span><br></pre></td></tr></table></figure>

<h3 id="Explore-the-Modules"><a href="#Explore-the-Modules" class="headerlink" title="Explore the Modules"></a>Explore the Modules</h3><p>对于 Transformer 处理的每个流程，可以在 <a target="_blank" rel="noopener" href="https://github.com/jiaweiHu-XDU/a-TransformerPractice/blob/master/main.ipynb">Jupyter Notebook</a> 中单步演示。</p>
<p>为了更好地体验，可以结合 <em>The Transformer Architecture: A Visual Guide</em> [2] 对比分析。</p>
<h3 id="Training-the-Models"><a href="#Training-the-Models" class="headerlink" title="Training the Models"></a>Training the Models</h3><p>一次性训练文本翻译器，可以通过以下命令：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python main.py --epochs <span class="number">1000</span> &gt; output/output.log</span><br></pre></td></tr></table></figure>

<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li>[1] <a target="_blank" rel="noopener" href="https://mina-ghashami.github.io/posts/2023-01-10-transformer/">Transformer: Concept and code from scratch</a></li>
<li>[2] <a target="_blank" rel="noopener" href="https://www.hendrik-erz.de/post/the-transformer-architecture-a-visual-guide-pdf-download">The Transformer Architecture: A Visual Guide</a></li>
</ul>
</div><div class="article-licensing box"><div class="licensing-title"><p>Transformer Concept Exploration and Practice in Pytorch</p><p><a href="https://jiaweihu-xdu.github.io/projects/a TransformerPractice/">https://jiaweihu-xdu.github.io/projects/a TransformerPractice/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Jiawei Hu</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2024-11-29</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2024-11-29</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><hr style="height:1px;margin:1rem 0"><div class="level is-mobile is-flex"><div class="article-tags is-size-7 is-uppercase"><i class="fas fa-tags has-text-grey"></i> <a class="link-muted" rel="tag" href="/tags/Transformer/">Transformer,</a><a class="link-muted" rel="tag" href="/tags/NLP/">NLP </a></div></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=64ad5faad2ddeb0019614bc5&amp;product=inline-share-buttons&amp;source=platform" defer></script></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/img/alipay.png" alt="Alipay"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/img/wechat.png" alt="Wechat"></span></a><a class="button donate" href="https://www.buymeacoffee.com/DustValor" target="_blank" rel="noopener" data-type="buymeacoffee"><span class="icon is-small"><i class="fas fa-coffee"></i></span><span>Buy me a coffee</span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/projects/%E5%9B%BE%E5%83%8F%E5%AD%A6%E5%A4%A7%E4%BD%9C%E4%B8%9A%EF%BC%9A3DGS/"><span class="level-item">3D Gaussian Splatting 真实场景的光场图像渲染</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="disqus_thread"><noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript></div><script>var disqus_config = function () {
            this.page.url = 'https://jiaweihu-xdu.github.io/projects/a%20TransformerPractice/';
            this.page.identifier = 'projects/a TransformerPractice/';
        };
        (function() {
            var d = document, s = d.createElement('script');  
            s.src = '//' + 'eblog-5' + '.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
        })();</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-96x96 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.jpg" alt="Jiawei Hu"></figure><p class="title is-size-4 is-block" style="line-height: 'inherit'; font-family: Times New Roman">Jiawei Hu</p><p style="white-space: pre-line; font-style: italic; font-family: Times New Roman; margin-bottom: 0.50rem; font-size: 1.0em">Computer Science
Machine Learning
</p><p class="is-size-5 is-flex justify-content-center" style="font-family: Times New Roman"><i class="fas fa-map-marker-alt mr-1"></i><span>Xidian University, China</span></p></div></div></nav><nav class="level menu-list is-mobile" style="margin-bottom:1rem"><a class="level-item has-text-centered is-marginless" href="/archives"><div><p class="heading">Posts</p><div><p class="title">36</p></div></div></a><a class="level-item has-text-centered is-marginless" href="/categories"><div><p class="heading">Categories</p><div><p class="title">6</p></div></div></a><a class="level-item has-text-centered is-marginless" href="/tags"><div><p class="heading">Tags</p><div><p class="title">27</p></div></div></a></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/JiaweiHu-XDU" target="_blank" rel="noopener"><i class="fab fa-github"></i>  Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/JiaweiHu-XDU"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Cnblog" href="https://www.cnblogs.com/MarkStiff/"><i class="fa-brands fa-blogger"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Notion" href="https://zhihaoli.notion.site/"><i class="fa-solid fa-desktop"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="mailto:jiaweihu_xdu@163.com"><i class="fa-solid fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="QQ" href="tencent://AddContact/?fromId=45&amp;fromSubId=1&amp;subcmd=all&amp;uin=1444980878&amp;website=www.oicqzone.com"><i class="fab fa-qq"></i></a></div></div></div><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#Introduction"><span class="level-left"><span class="level-item">1</span><span class="level-item">Introduction</span></span></a></li><li><a class="level is-mobile" href="#Understanding-of-Theories"><span class="level-left"><span class="level-item">2</span><span class="level-item">Understanding of Theories</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Tokenizer-amp-Embedding"><span class="level-left"><span class="level-item">2.1</span><span class="level-item">Tokenizer &amp; Embedding</span></span></a></li><li><a class="level is-mobile" href="#Position-Embedding"><span class="level-left"><span class="level-item">2.2</span><span class="level-item">Position Embedding</span></span></a></li><li><a class="level is-mobile" href="#Encoder"><span class="level-left"><span class="level-item">2.3</span><span class="level-item">Encoder</span></span></a></li><li><a class="level is-mobile" href="#"><span class="level-left"><span class="level-item">2.4</span><span class="level-item">Residual Connection</span></span></a></li><li><a class="level is-mobile" href="#"><span class="level-left"><span class="level-item">2.5</span><span class="level-item">Layer Normalization</span></span></a></li><li><a class="level is-mobile" href="#Multi-Head-Attention"><span class="level-left"><span class="level-item">2.6</span><span class="level-item">Multi-Head Attention</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Self-Head-Attention"><span class="level-left"><span class="level-item">2.6.1</span><span class="level-item">Self-Head Attention</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Feed-Forward-Network"><span class="level-left"><span class="level-item">2.7</span><span class="level-item">Feed-Forward Network</span></span></a></li><li><a class="level is-mobile" href="#Decoder"><span class="level-left"><span class="level-item">2.8</span><span class="level-item">Decoder</span></span></a></li><li><a class="level is-mobile" href="#Transformer"><span class="level-left"><span class="level-item">2.9</span><span class="level-item">Transformer</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Exploration-From-Scratch"><span class="level-left"><span class="level-item">3</span><span class="level-item">Exploration From Scratch</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Preparation"><span class="level-left"><span class="level-item">3.1</span><span class="level-item">Preparation</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#Clone-Project"><span class="level-left"><span class="level-item">3.1.1</span><span class="level-item">Clone Project</span></span></a></li><li><a class="level is-mobile" href="#Install-Conda-Environment"><span class="level-left"><span class="level-item">3.1.2</span><span class="level-item">Install Conda Environment</span></span></a></li><li><a class="level is-mobile" href="#Download-the-Dataset"><span class="level-left"><span class="level-item">3.1.3</span><span class="level-item">Download the Dataset</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Explore-the-Modules"><span class="level-left"><span class="level-item">3.2</span><span class="level-item">Explore the Modules</span></span></a></li><li><a class="level is-mobile" href="#Training-the-Models"><span class="level-left"><span class="level-item">3.3</span><span class="level-item">Training the Models</span></span></a></li></ul></li><li><a class="level is-mobile" href="#Reference"><span class="level-left"><span class="level-item">4</span><span class="level-item">Reference</span></span></a></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/blog/"><span class="level-start"><span class="level-item">blog</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile" href="/collaboration/"><span class="level-start"><span class="level-item">collaboration</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile" href="/knowledge/"><span class="level-start"><span class="level-item">knowledge</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/life/"><span class="level-start"><span class="level-item">life</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/projects/"><span class="level-start"><span class="level-item">projects</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/readings/"><span class="level-start"><span class="level-item">readings</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/3D-Vision/"><span class="tag">3D Vision</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/3DGS/"><span class="tag">3DGS</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Collaboration-Project/"><span class="tag">Collaboration Project</span><span class="tag">8</span></a></div><div class="control"><a class="tags has-addons" href="/tags/College-Life/"><span class="tag">College Life</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-Network/"><span class="tag">Computer Network</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-Principle/"><span class="tag">Computer Principle</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Computer-Vision/"><span class="tag">Computer Vision</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Data-Visualization/"><span class="tag">Data Visualization</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-Learning/"><span class="tag">Deep Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Deep-Reinforcement-Learning/"><span class="tag">Deep Reinforcement Learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Eletromagnetic-B%E6%B5%8B/"><span class="tag">Eletromagnetic B测</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Eletromagnetic-Physics/"><span class="tag">Eletromagnetic Physics</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Embedded-System/"><span class="tag">Embedded System</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Health/"><span class="tag">Health</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hexo/"><span class="tag">Hexo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Life-Knowledge/"><span class="tag">Life Knowledge</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Life-Wisdom/"><span class="tag">Life Wisdom</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Literature-Survey/"><span class="tag">Literature Survey</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Machine-Learning/"><span class="tag">Machine Learning</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Mathematical-Modeling/"><span class="tag">Mathematical Modeling</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Microcomputer/"><span class="tag">Microcomputer</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OpenSSL/"><span class="tag">OpenSSL</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Professional-Knowledge/"><span class="tag">Professional Knowledge</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Project-Tools/"><span class="tag">Project Tools</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Reinforcement-Learning/"><span class="tag">Reinforcement Learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Transformer/"><span class="tag">Transformer</span><span class="tag">1</span></a></div></div></div></div></div></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="Jiawei Hu - Jiawei Hu&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2023-2024 Jiawei Hu</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv"><span id="busuanzi_container_site_uv">Site UV: <span id="busuanzi_value_site_uv"></span></span>   <span id="busuanzi_container_site_pv">Site PV: <span id="busuanzi_value_site_pv"></span></span></span></p><p class="is-size-7"> </p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="GitHub" href="https://github.com/jiaweiHu-XDU/jiaweiHu-XDU.github.io"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><script src="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/js/lightgallery.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/katex.min.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/katex.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/contrib/auto-render.min.js" defer></script><script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.15.1/contrib/mhchem.min.js" defer></script><script>window.addEventListener("load", function() {
            document.querySelectorAll('[role="article"] > .content').forEach(function(element) {
                renderMathInElement(element);
            });
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><script src="/js/main.js" defer></script><script src="/js/night.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><div id="dark" onclick="switchDarkMode()"></div><script type="text/javascript" src="/js/universe.js"></script></body></html>